{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqLrTPv8b7le"
   },
   "source": [
    "# How-to guide for Personalized Recommendations use-case on Abacus.AI platform\n",
    "This notebook provides you with a hands on environment to build a model that creates personalized recommendations using the Abacus.AI Python Client Library.\n",
    "\n",
    "We'll be using the [User Item Recommendations](https://s3.amazonaws.com//realityengines.exampledatasets/user_recommendations/user_movie_ratings.csv), [Movie Attributes](https://s3.amazonaws.com//realityengines.exampledatasets/user_recommendations/movies_metadata.csv), and [User Attributes](https://s3.amazonaws.com//realityengines.exampledatasets/user_recommendations/users_metadata.csv) datasets, each of which has information about the user and/or their choice of movies.\n",
    "\n",
    "\n",
    "## Table of content\n",
    "[Installation and imports](#scrollTo=-CHABbdhcDZg)\n",
    "\n",
    "[1. Create a Project](#scrollTo=j_6LiH43cM9Z)\n",
    "\n",
    "[2. Add Datasets to your Project](#scrollTo=8O41vBUQcgxN)\n",
    "\n",
    "[3. Train a Model](#scrollTo=RWvYvPEmdfg7)\n",
    "\n",
    "[(Checkpoint)](#scrollTo=C0mIg2VHdnfA)\n",
    "\n",
    "[4. Evaluate your Model Metrics](#scrollTo=jBK2e1WNd6L3)\n",
    "\n",
    "[5. Deploy Model](#scrollTo=Xc5YAK8veBt1)\n",
    "\n",
    "[6. Make Prediction](#scrollTo=BzFpIsJ_eGmk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CHABbdhcDZg"
   },
   "source": [
    "## Installation and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-2wF3btAglZ"
   },
   "source": [
    "1. Install the Abacus.AI library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6394,
     "status": "ok",
     "timestamp": 1609877999687,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "-wgbLfJjtBoE",
    "outputId": "28382897-dad5-404c-8f36-8047112c1f89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: abacusai in /home/saim/.local/lib/python3.8/site-packages (0.32.9)\n",
      "Requirement already satisfied: fastavro in /home/saim/.local/lib/python3.8/site-packages (from abacusai) (1.4.7)\n",
      "Requirement already satisfied: packaging in /home/saim/.local/lib/python3.8/site-packages (from abacusai) (21.3)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from abacusai) (2.22.0)\n",
      "Requirement already satisfied: pandas in /home/saim/.local/lib/python3.8/site-packages (from abacusai) (1.3.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/saim/.local/lib/python3.8/site-packages (from packaging->abacusai) (3.0.6)\n",
      "Requirement already satisfied: numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in /home/saim/.local/lib/python3.8/site-packages (from pandas->abacusai) (1.21.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3/dist-packages (from pandas->abacusai) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas->abacusai) (2019.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install abacusai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EYIz02FcFEo"
   },
   "source": [
    "We'll also import pandas for visualization in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7857,
     "status": "ok",
     "timestamp": 1609878002257,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "VGTCGEUntL9Z",
    "outputId": "e1240fbe-c206-43c9-f7ae-eb6ae9f63fa2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd  # A tool we'll use to download and preview CSV files\n",
    "pd.set_option('display.max_colwidth', None)  # We set the max_colwidth to None to have an unlimited width of characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YEZVhZaYcGon"
   },
   "source": [
    "2. Add your Abacus.AI [API Key](https://abacus.ai/app/profile/apikey) generated using the API dashboard as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 672,
     "status": "ok",
     "timestamp": 1609878135718,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "Py71-cbbtNKX"
   },
   "outputs": [],
   "source": [
    "#@title Abacus.AI API Key\n",
    "api_key = '2fdecde877dc45fab937eff82b70eff0'  #@param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBcZRI2_cIe2"
   },
   "source": [
    "3. Import the Abacus.AI library and instantiate a client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1424,
     "status": "ok",
     "timestamp": 1609878139367,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "z5xwrkD6tOVT"
   },
   "outputs": [],
   "source": [
    "from abacusai import ApiClient\n",
    "client = ApiClient(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_6LiH43cM9Z"
   },
   "source": [
    "## 1. Create a Project\n",
    "\n",
    "Abacus.AI projects are containers that have datasets and trained models. By specifying a business **Use Case**, Abacus.AI tailors the deep learning algorithms to produce the best performing model possible for your data.\n",
    "\n",
    "We'll call the `list_use_cases` method to retrieve a list of the available Use Cases currently available on the Abacus.AI platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 747,
     "status": "ok",
     "timestamp": 1609878140975,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "ZnIKg-SutPZU",
    "outputId": "87f1e871-0ad5-4f22-8fd2-9b30d0e4a22b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[UseCase(use_case='UCPLUGANDPLAY',\n",
       "   pretty_name='Plug & Play Your Tensorflow Model',\n",
       "   description='Upload your already trained model and leverage our model serving infrastructure.. Host your models on our infrastructure and get a JSON api with auto scaling and more!'),\n",
       " UseCase(use_case='EMBEDDINGS_ONLY',\n",
       "   pretty_name='Vector Matching Engine',\n",
       "   description='Upload embeddings and leverage our similarity search infrastructure.. Scale to high traffic, update your index in near realtime'),\n",
       " UseCase(use_case='MODEL_WITH_EMBEDDINGS',\n",
       "   pretty_name='Tensorflow Model With Vector Matching Engine',\n",
       "   description='Upload your already trained model and leverage our model serving infrastructure.. Host your models on our infrastructure and get a JSON api with auto scaling and more!'),\n",
       " UseCase(use_case='TORCH_MODEL_WITH_EMBEDDINGS',\n",
       "   pretty_name='PyTorch Model With Vector Matching Engine',\n",
       "   description='Upload your already trained model and leverage our model serving infrastructure.. Host your models on our infrastructure and get a JSON api with auto scaling and more!'),\n",
       " UseCase(use_case='PYTHON_MODEL',\n",
       "   pretty_name='Custom Python Model',\n",
       "   description='Upload your training code and let Abacus.AI handle training. Host your models on our infrastructure and get a JSON api with auto scaling and more!'),\n",
       " UseCase(use_case='DOCKER_MODEL',\n",
       "   pretty_name='Plug & Play Your Dockerized Model',\n",
       "   description='Upload your already trained model and leverage our model serving infrastructure.. Host your models on our infrastructure and get a JSON api with auto scaling and more!'),\n",
       " UseCase(use_case='DOCKER_MODEL_WITH_EMBEDDINGS',\n",
       "   pretty_name='Plug & Play Your Dockerized Model with Vector Matching Engine',\n",
       "   description='Upload your already trained model and leverage our model serving infrastructure.. Host your models on our infrastructure and get a JSON api with auto scaling and more!'),\n",
       " UseCase(use_case='CUSTOMER_CHURN',\n",
       "   pretty_name='Customer Churn Prediction',\n",
       "   description='Identify customers who are most likely to churn out of your system and send them marketing promotions/emails to retain them. Deploy a real-time deep learning model that identifies customers who are most likely to leave and increase retention.'),\n",
       " UseCase(use_case='ENERGY',\n",
       "   pretty_name='Real-Time Forecasting',\n",
       "   description='Accurately forecast energy or computation usage in real-time. Make downstream planning decisions based on your predictions. We use generative modeling (GANs) to augment your dataset with synthetic data. This unique approach allows us to make accurate predictions in real-time, even when you have little historical data.'),\n",
       " UseCase(use_case='FINANCIAL_METRICS',\n",
       "   pretty_name='Financial Metrics Forecasting',\n",
       "   description='Accurately plan your cash flow, revenue, and sales with state-of-the-art deep learning-based forecasting. We use generative modeling (GANs) to augment your dataset with synthetic data. This unique approach allows us to make accurate predictions, even when you have little historical data.'),\n",
       " UseCase(use_case='FRAUD_ACCOUNT',\n",
       "   pretty_name='Account Takeover and Defense',\n",
       "   description=\"Shield your customers from account takeovers by blocking bots and fake sign-ups. Behind the scenes, our AI engine will develop a custom deep learning model to prevent bot attacks and stops account takeovers in real-time. Setup is super simple and doesn't require any engineering or cumbersome data preparation.\"),\n",
       " UseCase(use_case='FRAUD_THREAT',\n",
       "   pretty_name='Intelligent Threat Detection',\n",
       "   description=\"Stop breachers in their tracks by continuously monitoring your environment for malicious activity. Prevent alert fatigue by reducing the number of false positives over time. Behind the scenes, our AI engine develops a deep learning model customized for your data to continuously monitors all your logs and alerts you of any malicious activity. Setup is super simple and doesn't require any ML expertise.\"),\n",
       " UseCase(use_case='FRAUD_TRANSACTIONS',\n",
       "   pretty_name='Transaction/Credit Card Fraud',\n",
       "   description=\"Accept payments with confidence, reduce chargebacks, and catch payment fraud instantly as it happens. Behind the scenes, our AI engine develops a custom deep learning model for you that prevents transaction fraud and catches fraudsters in real-time. Set up is super simple and doesn't require any engineering and cumbersome data preparation.\"),\n",
       " UseCase(use_case='OPERATIONS_CLOUD',\n",
       "   pretty_name='Cloud Spend Alerts',\n",
       "   description='Deploy state-of-the-art deep learning models to monitor your cloud spend, spot anomalies, spot runaway incidents, mitigate cost incidents, and get alerts so they can be remedied as quickly as possible. Use deep learning to find anomalies in your cloud usage and get alerts on them to mitigate cost incidents.'),\n",
       " UseCase(use_case='CLOUD_SPEND',\n",
       "   pretty_name='Cloud Spend Alerts',\n",
       "   description='Deploy state-of-the-art deep learning models to monitor your cloud spend, spot anomalies, spot runaway incidents, mitigate cost incidents, and get alerts so they can be remedied as quickly as possible. Use deep learning to find anomalies in your cloud usage and get alerts on them to mitigate cost incidents.'),\n",
       " UseCase(use_case='TIMESERIES_ANOMALY_DETECTION',\n",
       "   pretty_name='Timeseries Anomaly Detection',\n",
       "   description='Spot anomalies in your time series data by using deep learning models to increase revenue, save costs and reduce risks. With Abacus.AI you can set up state of the art deep learning models for time series anomaly detection within hours. These models adjust in real time and spot both simple one dimensional and complex multidimensional anomalies. Our models also help you find the root cause of the anomalies. No cumbersome data preparation or engineering effort to deploy the models in production are required.'),\n",
       " UseCase(use_case='OPERATIONS_MAINTENANCE',\n",
       "   pretty_name='Predictive Maintenance',\n",
       "   description='Leverage deep learning models to proactively assess the health of your assets and perform timely maintenance to reduce downtime and save costs. With Abacus.ai you can set up state of the art deep learning models for predictive maintenance within hours. These models learn from your past failures as well as spot anomalies that can lead to new failures. No cumbersome data preparation or engineering effort to deploy the models in production is required.'),\n",
       " UseCase(use_case='PERS_PROMOTIONS',\n",
       "   pretty_name='Personalized Promotions',\n",
       "   description='Send personalized promotions to your customers and increase engagement. Personalize promotions based on catalog items, marketing messages, delivery channels, and discount terms. Deploy a real-time deep learning model that targets relevant promotions to customers and increases engagement. No cumbersome data preparation required and setup is super easy.'),\n",
       " UseCase(use_case='PREDICTING',\n",
       "   pretty_name='Predictive Modeling',\n",
       "   description='Use historical data to predict future occurrences. Train state-of-the-art predictive models customized specifically according to your data and deploy it in production in hours, not months!. You can create a deep learning model for your specific needs simply by pointing us to your data and specifying the inputs/outputs. Our expert AI engine will do the data cleaning and processing, algorithm selection (classification or regression), and model creation. You will be ready to generate intelligent predictions from the deployed model in production in just a few hours.'),\n",
       " UseCase(use_case='RETAIL',\n",
       "   pretty_name='Demand Forecasting',\n",
       "   description='Accurately forecast retail demand. We use generative modeling (GANs) to augment your dataset with synthetic data. This allows us to make accurate predictions even when you have little historical data.'),\n",
       " UseCase(use_case='SALES_FORECASTING',\n",
       "   pretty_name='Sales and Revenue Forecasting',\n",
       "   description='Forecast sales and revenue across your sales reps, products, business units, and locations. Use deep learning to forecast your sales across multiple dimensions. Make better planning discussions and anticipate future problems so you can mitigate them.'),\n",
       " UseCase(use_case='SALES_SCORING',\n",
       "   pretty_name='Predictive Lead Scoring',\n",
       "   description='Identify the sales leads that are most likely to convert into paying customers and increase revenue. Just point our AI engine to your data, and it will create a deep learning model customized for your data to score all your leads and identify the best ones for conversion.'),\n",
       " UseCase(use_case='USER_RANKINGS',\n",
       "   pretty_name='Personalized Search',\n",
       "   description='Re-rank search results or list of items based on a user preferences. Maximize user engagement and revenue. Our unique blend of reinforcement learning and deep learning-based technology works even when you have little historical data and have to deal with a fast-changing catalog or multiple new users.'),\n",
       " UseCase(use_case='NAMED_ENTITY_RECOGNITION',\n",
       "   pretty_name='Text extraction and classification',\n",
       "   description='Find and label fields within text documents such as emails, chats, receipts, invoices or any other unstructured data set. With Abacus.AI you can set up state of the art deep learning models for text extraction and classification within hours. Based on your specific domain and use-case, Abacus.AI can fine-tune pre-trained models, apply transfer learning or simply train new language models from scratch.  No cumbersome data preparation or engineering effort to deploy the models in production are required.'),\n",
       " UseCase(use_case='USER_RECOMMENDATIONS',\n",
       "   pretty_name='Personalized Recommendations',\n",
       "   description='Increase user engagement and revenue with personalized recommendations on your app/website. Our unique blend of reinforcement learning and deep learning-based technology works even when you have little historical data and have to deal with a fast-changing catalog or multiple new users.'),\n",
       " UseCase(use_case='USER_RELATED',\n",
       "   pretty_name='Related Items',\n",
       "   description='Maximize revenue and user engagement. Immerse your customers into your app/website by providing them with a rich browse and related items experience. Our unique blend of reinforcement learning and deep learning-based technology works even when you have little historical data and have to deal with a fast-changing catalog or multiple new users.'),\n",
       " UseCase(use_case='VISION',\n",
       "   pretty_name='Image Classification & Detection',\n",
       "   description='Train an image classification & detection model specific to your domain and use it to classify and detect relevant objects. With Abacus.AI you can set up state of the art deep learning models for Image classification & detection within hours. Based on your specific domain and use-case, Abacus.AI can fine-tune pre-trained models, apply transfer learning or simply train new vision models from scratch. No cumbersome data preparation or engineering effort to deploy the models in production are required.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cases = client.list_use_cases()\n",
    "use_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X824DYzaBrg7"
   },
   "source": [
    "We can use pandas to pretty-print the use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 660,
     "status": "ok",
     "timestamp": 1609878144039,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "WYqJor8HB46J",
    "outputId": "6b654d86-6c28-4386-e7d3-b6ed4c6c56b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>use_case</th>\n",
       "      <th>pretty_name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCPLUGANDPLAY</td>\n",
       "      <td>Plug &amp; Play Your Tensorflow Model</td>\n",
       "      <td>Upload your already trained model and leverage our model serving infrastructure.. Host your models on our infrastructure and get a JSON api with auto scaling and more!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMBEDDINGS_ONLY</td>\n",
       "      <td>Vector Matching Engine</td>\n",
       "      <td>Upload embeddings and leverage our similarity search infrastructure.. Scale to high traffic, update your index in near realtime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MODEL_WITH_EMBEDDINGS</td>\n",
       "      <td>Tensorflow Model With Vector Matching Engine</td>\n",
       "      <td>Upload your already trained model and leverage our model serving infrastructure.. Host your models on our infrastructure and get a JSON api with auto scaling and more!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TORCH_MODEL_WITH_EMBEDDINGS</td>\n",
       "      <td>PyTorch Model With Vector Matching Engine</td>\n",
       "      <td>Upload your already trained model and leverage our model serving infrastructure.. Host your models on our infrastructure and get a JSON api with auto scaling and more!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PYTHON_MODEL</td>\n",
       "      <td>Custom Python Model</td>\n",
       "      <td>Upload your training code and let Abacus.AI handle training. Host your models on our infrastructure and get a JSON api with auto scaling and more!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DOCKER_MODEL</td>\n",
       "      <td>Plug &amp; Play Your Dockerized Model</td>\n",
       "      <td>Upload your already trained model and leverage our model serving infrastructure.. Host your models on our infrastructure and get a JSON api with auto scaling and more!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DOCKER_MODEL_WITH_EMBEDDINGS</td>\n",
       "      <td>Plug &amp; Play Your Dockerized Model with Vector Matching Engine</td>\n",
       "      <td>Upload your already trained model and leverage our model serving infrastructure.. Host your models on our infrastructure and get a JSON api with auto scaling and more!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CUSTOMER_CHURN</td>\n",
       "      <td>Customer Churn Prediction</td>\n",
       "      <td>Identify customers who are most likely to churn out of your system and send them marketing promotions/emails to retain them. Deploy a real-time deep learning model that identifies customers who are most likely to leave and increase retention.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ENERGY</td>\n",
       "      <td>Real-Time Forecasting</td>\n",
       "      <td>Accurately forecast energy or computation usage in real-time. Make downstream planning decisions based on your predictions. We use generative modeling (GANs) to augment your dataset with synthetic data. This unique approach allows us to make accurate predictions in real-time, even when you have little historical data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FINANCIAL_METRICS</td>\n",
       "      <td>Financial Metrics Forecasting</td>\n",
       "      <td>Accurately plan your cash flow, revenue, and sales with state-of-the-art deep learning-based forecasting. We use generative modeling (GANs) to augment your dataset with synthetic data. This unique approach allows us to make accurate predictions, even when you have little historical data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FRAUD_ACCOUNT</td>\n",
       "      <td>Account Takeover and Defense</td>\n",
       "      <td>Shield your customers from account takeovers by blocking bots and fake sign-ups. Behind the scenes, our AI engine will develop a custom deep learning model to prevent bot attacks and stops account takeovers in real-time. Setup is super simple and doesn't require any engineering or cumbersome data preparation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FRAUD_THREAT</td>\n",
       "      <td>Intelligent Threat Detection</td>\n",
       "      <td>Stop breachers in their tracks by continuously monitoring your environment for malicious activity. Prevent alert fatigue by reducing the number of false positives over time. Behind the scenes, our AI engine develops a deep learning model customized for your data to continuously monitors all your logs and alerts you of any malicious activity. Setup is super simple and doesn't require any ML expertise.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FRAUD_TRANSACTIONS</td>\n",
       "      <td>Transaction/Credit Card Fraud</td>\n",
       "      <td>Accept payments with confidence, reduce chargebacks, and catch payment fraud instantly as it happens. Behind the scenes, our AI engine develops a custom deep learning model for you that prevents transaction fraud and catches fraudsters in real-time. Set up is super simple and doesn't require any engineering and cumbersome data preparation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>OPERATIONS_CLOUD</td>\n",
       "      <td>Cloud Spend Alerts</td>\n",
       "      <td>Deploy state-of-the-art deep learning models to monitor your cloud spend, spot anomalies, spot runaway incidents, mitigate cost incidents, and get alerts so they can be remedied as quickly as possible. Use deep learning to find anomalies in your cloud usage and get alerts on them to mitigate cost incidents.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CLOUD_SPEND</td>\n",
       "      <td>Cloud Spend Alerts</td>\n",
       "      <td>Deploy state-of-the-art deep learning models to monitor your cloud spend, spot anomalies, spot runaway incidents, mitigate cost incidents, and get alerts so they can be remedied as quickly as possible. Use deep learning to find anomalies in your cloud usage and get alerts on them to mitigate cost incidents.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TIMESERIES_ANOMALY_DETECTION</td>\n",
       "      <td>Timeseries Anomaly Detection</td>\n",
       "      <td>Spot anomalies in your time series data by using deep learning models to increase revenue, save costs and reduce risks. With Abacus.AI you can set up state of the art deep learning models for time series anomaly detection within hours. These models adjust in real time and spot both simple one dimensional and complex multidimensional anomalies. Our models also help you find the root cause of the anomalies. No cumbersome data preparation or engineering effort to deploy the models in production are required.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>OPERATIONS_MAINTENANCE</td>\n",
       "      <td>Predictive Maintenance</td>\n",
       "      <td>Leverage deep learning models to proactively assess the health of your assets and perform timely maintenance to reduce downtime and save costs. With Abacus.ai you can set up state of the art deep learning models for predictive maintenance within hours. These models learn from your past failures as well as spot anomalies that can lead to new failures. No cumbersome data preparation or engineering effort to deploy the models in production is required.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PERS_PROMOTIONS</td>\n",
       "      <td>Personalized Promotions</td>\n",
       "      <td>Send personalized promotions to your customers and increase engagement. Personalize promotions based on catalog items, marketing messages, delivery channels, and discount terms. Deploy a real-time deep learning model that targets relevant promotions to customers and increases engagement. No cumbersome data preparation required and setup is super easy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PREDICTING</td>\n",
       "      <td>Predictive Modeling</td>\n",
       "      <td>Use historical data to predict future occurrences. Train state-of-the-art predictive models customized specifically according to your data and deploy it in production in hours, not months!. You can create a deep learning model for your specific needs simply by pointing us to your data and specifying the inputs/outputs. Our expert AI engine will do the data cleaning and processing, algorithm selection (classification or regression), and model creation. You will be ready to generate intelligent predictions from the deployed model in production in just a few hours.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RETAIL</td>\n",
       "      <td>Demand Forecasting</td>\n",
       "      <td>Accurately forecast retail demand. We use generative modeling (GANs) to augment your dataset with synthetic data. This allows us to make accurate predictions even when you have little historical data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SALES_FORECASTING</td>\n",
       "      <td>Sales and Revenue Forecasting</td>\n",
       "      <td>Forecast sales and revenue across your sales reps, products, business units, and locations. Use deep learning to forecast your sales across multiple dimensions. Make better planning discussions and anticipate future problems so you can mitigate them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SALES_SCORING</td>\n",
       "      <td>Predictive Lead Scoring</td>\n",
       "      <td>Identify the sales leads that are most likely to convert into paying customers and increase revenue. Just point our AI engine to your data, and it will create a deep learning model customized for your data to score all your leads and identify the best ones for conversion.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>USER_RANKINGS</td>\n",
       "      <td>Personalized Search</td>\n",
       "      <td>Re-rank search results or list of items based on a user preferences. Maximize user engagement and revenue. Our unique blend of reinforcement learning and deep learning-based technology works even when you have little historical data and have to deal with a fast-changing catalog or multiple new users.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NAMED_ENTITY_RECOGNITION</td>\n",
       "      <td>Text extraction and classification</td>\n",
       "      <td>Find and label fields within text documents such as emails, chats, receipts, invoices or any other unstructured data set. With Abacus.AI you can set up state of the art deep learning models for text extraction and classification within hours. Based on your specific domain and use-case, Abacus.AI can fine-tune pre-trained models, apply transfer learning or simply train new language models from scratch.  No cumbersome data preparation or engineering effort to deploy the models in production are required.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>USER_RECOMMENDATIONS</td>\n",
       "      <td>Personalized Recommendations</td>\n",
       "      <td>Increase user engagement and revenue with personalized recommendations on your app/website. Our unique blend of reinforcement learning and deep learning-based technology works even when you have little historical data and have to deal with a fast-changing catalog or multiple new users.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>USER_RELATED</td>\n",
       "      <td>Related Items</td>\n",
       "      <td>Maximize revenue and user engagement. Immerse your customers into your app/website by providing them with a rich browse and related items experience. Our unique blend of reinforcement learning and deep learning-based technology works even when you have little historical data and have to deal with a fast-changing catalog or multiple new users.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>VISION</td>\n",
       "      <td>Image Classification &amp; Detection</td>\n",
       "      <td>Train an image classification &amp; detection model specific to your domain and use it to classify and detect relevant objects. With Abacus.AI you can set up state of the art deep learning models for Image classification &amp; detection within hours. Based on your specific domain and use-case, Abacus.AI can fine-tune pre-trained models, apply transfer learning or simply train new vision models from scratch. No cumbersome data preparation or engineering effort to deploy the models in production are required.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        use_case  \\\n",
       "0                  UCPLUGANDPLAY   \n",
       "1                EMBEDDINGS_ONLY   \n",
       "2          MODEL_WITH_EMBEDDINGS   \n",
       "3    TORCH_MODEL_WITH_EMBEDDINGS   \n",
       "4                   PYTHON_MODEL   \n",
       "5                   DOCKER_MODEL   \n",
       "6   DOCKER_MODEL_WITH_EMBEDDINGS   \n",
       "7                 CUSTOMER_CHURN   \n",
       "8                         ENERGY   \n",
       "9              FINANCIAL_METRICS   \n",
       "10                 FRAUD_ACCOUNT   \n",
       "11                  FRAUD_THREAT   \n",
       "12            FRAUD_TRANSACTIONS   \n",
       "13              OPERATIONS_CLOUD   \n",
       "14                   CLOUD_SPEND   \n",
       "15  TIMESERIES_ANOMALY_DETECTION   \n",
       "16        OPERATIONS_MAINTENANCE   \n",
       "17               PERS_PROMOTIONS   \n",
       "18                    PREDICTING   \n",
       "19                        RETAIL   \n",
       "20             SALES_FORECASTING   \n",
       "21                 SALES_SCORING   \n",
       "22                 USER_RANKINGS   \n",
       "23      NAMED_ENTITY_RECOGNITION   \n",
       "24          USER_RECOMMENDATIONS   \n",
       "25                  USER_RELATED   \n",
       "26                        VISION   \n",
       "\n",
       "                                                      pretty_name  \\\n",
       "0                               Plug & Play Your Tensorflow Model   \n",
       "1                                          Vector Matching Engine   \n",
       "2                    Tensorflow Model With Vector Matching Engine   \n",
       "3                       PyTorch Model With Vector Matching Engine   \n",
       "4                                             Custom Python Model   \n",
       "5                               Plug & Play Your Dockerized Model   \n",
       "6   Plug & Play Your Dockerized Model with Vector Matching Engine   \n",
       "7                                       Customer Churn Prediction   \n",
       "8                                           Real-Time Forecasting   \n",
       "9                                   Financial Metrics Forecasting   \n",
       "10                                   Account Takeover and Defense   \n",
       "11                                   Intelligent Threat Detection   \n",
       "12                                  Transaction/Credit Card Fraud   \n",
       "13                                             Cloud Spend Alerts   \n",
       "14                                             Cloud Spend Alerts   \n",
       "15                                   Timeseries Anomaly Detection   \n",
       "16                                         Predictive Maintenance   \n",
       "17                                        Personalized Promotions   \n",
       "18                                            Predictive Modeling   \n",
       "19                                             Demand Forecasting   \n",
       "20                                  Sales and Revenue Forecasting   \n",
       "21                                        Predictive Lead Scoring   \n",
       "22                                            Personalized Search   \n",
       "23                             Text extraction and classification   \n",
       "24                                   Personalized Recommendations   \n",
       "25                                                  Related Items   \n",
       "26                               Image Classification & Detection   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 description  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                    Upload your already trained model and leverage our model serving infrastructure.. Host your models on our infrastructure and get a JSON api with auto scaling and more!  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                            Upload embeddings and leverage our similarity search infrastructure.. Scale to high traffic, update your index in near realtime  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                    Upload your already trained model and leverage our model serving infrastructure.. Host your models on our infrastructure and get a JSON api with auto scaling and more!  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                    Upload your already trained model and leverage our model serving infrastructure.. Host your models on our infrastructure and get a JSON api with auto scaling and more!  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                         Upload your training code and let Abacus.AI handle training. Host your models on our infrastructure and get a JSON api with auto scaling and more!  \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                    Upload your already trained model and leverage our model serving infrastructure.. Host your models on our infrastructure and get a JSON api with auto scaling and more!  \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                    Upload your already trained model and leverage our model serving infrastructure.. Host your models on our infrastructure and get a JSON api with auto scaling and more!  \n",
       "7                                                                                                                                                                                                                                                                                                                                         Identify customers who are most likely to churn out of your system and send them marketing promotions/emails to retain them. Deploy a real-time deep learning model that identifies customers who are most likely to leave and increase retention.  \n",
       "8                                                                                                                                                                                                                                                            Accurately forecast energy or computation usage in real-time. Make downstream planning decisions based on your predictions. We use generative modeling (GANs) to augment your dataset with synthetic data. This unique approach allows us to make accurate predictions in real-time, even when you have little historical data.  \n",
       "9                                                                                                                                                                                                                                                                                           Accurately plan your cash flow, revenue, and sales with state-of-the-art deep learning-based forecasting. We use generative modeling (GANs) to augment your dataset with synthetic data. This unique approach allows us to make accurate predictions, even when you have little historical data.  \n",
       "10                                                                                                                                                                                                                                                                    Shield your customers from account takeovers by blocking bots and fake sign-ups. Behind the scenes, our AI engine will develop a custom deep learning model to prevent bot attacks and stops account takeovers in real-time. Setup is super simple and doesn't require any engineering or cumbersome data preparation.  \n",
       "11                                                                                                                                                                       Stop breachers in their tracks by continuously monitoring your environment for malicious activity. Prevent alert fatigue by reducing the number of false positives over time. Behind the scenes, our AI engine develops a deep learning model customized for your data to continuously monitors all your logs and alerts you of any malicious activity. Setup is super simple and doesn't require any ML expertise.  \n",
       "12                                                                                                                                                                                                                                     Accept payments with confidence, reduce chargebacks, and catch payment fraud instantly as it happens. Behind the scenes, our AI engine develops a custom deep learning model for you that prevents transaction fraud and catches fraudsters in real-time. Set up is super simple and doesn't require any engineering and cumbersome data preparation.  \n",
       "13                                                                                                                                                                                                                                                                      Deploy state-of-the-art deep learning models to monitor your cloud spend, spot anomalies, spot runaway incidents, mitigate cost incidents, and get alerts so they can be remedied as quickly as possible. Use deep learning to find anomalies in your cloud usage and get alerts on them to mitigate cost incidents.  \n",
       "14                                                                                                                                                                                                                                                                      Deploy state-of-the-art deep learning models to monitor your cloud spend, spot anomalies, spot runaway incidents, mitigate cost incidents, and get alerts so they can be remedied as quickly as possible. Use deep learning to find anomalies in your cloud usage and get alerts on them to mitigate cost incidents.  \n",
       "15                                                            Spot anomalies in your time series data by using deep learning models to increase revenue, save costs and reduce risks. With Abacus.AI you can set up state of the art deep learning models for time series anomaly detection within hours. These models adjust in real time and spot both simple one dimensional and complex multidimensional anomalies. Our models also help you find the root cause of the anomalies. No cumbersome data preparation or engineering effort to deploy the models in production are required.  \n",
       "16                                                                                                                     Leverage deep learning models to proactively assess the health of your assets and perform timely maintenance to reduce downtime and save costs. With Abacus.ai you can set up state of the art deep learning models for predictive maintenance within hours. These models learn from your past failures as well as spot anomalies that can lead to new failures. No cumbersome data preparation or engineering effort to deploy the models in production is required.  \n",
       "17                                                                                                                                                                                                                         Send personalized promotions to your customers and increase engagement. Personalize promotions based on catalog items, marketing messages, delivery channels, and discount terms. Deploy a real-time deep learning model that targets relevant promotions to customers and increases engagement. No cumbersome data preparation required and setup is super easy.  \n",
       "18  Use historical data to predict future occurrences. Train state-of-the-art predictive models customized specifically according to your data and deploy it in production in hours, not months!. You can create a deep learning model for your specific needs simply by pointing us to your data and specifying the inputs/outputs. Our expert AI engine will do the data cleaning and processing, algorithm selection (classification or regression), and model creation. You will be ready to generate intelligent predictions from the deployed model in production in just a few hours.  \n",
       "19                                                                                                                                                                                                                                                                                                                                                                                  Accurately forecast retail demand. We use generative modeling (GANs) to augment your dataset with synthetic data. This allows us to make accurate predictions even when you have little historical data.  \n",
       "20                                                                                                                                                                                                                                                                                                                                Forecast sales and revenue across your sales reps, products, business units, and locations. Use deep learning to forecast your sales across multiple dimensions. Make better planning discussions and anticipate future problems so you can mitigate them.  \n",
       "21                                                                                                                                                                                                                                                                                                          Identify the sales leads that are most likely to convert into paying customers and increase revenue. Just point our AI engine to your data, and it will create a deep learning model customized for your data to score all your leads and identify the best ones for conversion.  \n",
       "22                                                                                                                                                                                                                                                                             Re-rank search results or list of items based on a user preferences. Maximize user engagement and revenue. Our unique blend of reinforcement learning and deep learning-based technology works even when you have little historical data and have to deal with a fast-changing catalog or multiple new users.  \n",
       "23                                                               Find and label fields within text documents such as emails, chats, receipts, invoices or any other unstructured data set. With Abacus.AI you can set up state of the art deep learning models for text extraction and classification within hours. Based on your specific domain and use-case, Abacus.AI can fine-tune pre-trained models, apply transfer learning or simply train new language models from scratch.  No cumbersome data preparation or engineering effort to deploy the models in production are required.  \n",
       "24                                                                                                                                                                                                                                                                                            Increase user engagement and revenue with personalized recommendations on your app/website. Our unique blend of reinforcement learning and deep learning-based technology works even when you have little historical data and have to deal with a fast-changing catalog or multiple new users.  \n",
       "25                                                                                                                                                                                                                                  Maximize revenue and user engagement. Immerse your customers into your app/website by providing them with a rich browse and related items experience. Our unique blend of reinforcement learning and deep learning-based technology works even when you have little historical data and have to deal with a fast-changing catalog or multiple new users.  \n",
       "26                                                                  Train an image classification & detection model specific to your domain and use it to classify and detect relevant objects. With Abacus.AI you can set up state of the art deep learning models for Image classification & detection within hours. Based on your specific domain and use-case, Abacus.AI can fine-tune pre-trained models, apply transfer learning or simply train new vision models from scratch. No cumbersome data preparation or engineering effort to deploy the models in production are required.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(use_case.to_dict() for use_case in use_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHRg5caCcWq1"
   },
   "source": [
    "In this notebook, we're going to create a model that creates personalized recommendations using the User Item Recommendations, Movie Attributes, and User Attributes datasets. The **USER_RECOMMENDATIONS** use case is best tailored for this situation. For the purpose of taking an example, we will use the IMDB movie dataset that has movie metadata, user metadata, and user-movie ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 618,
     "status": "ok",
     "timestamp": 1609878147694,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "in9724URtQlL"
   },
   "outputs": [],
   "source": [
    "#@title Abacus.AI Use Case\n",
    "\n",
    "use_case = 'USER_RECOMMENDATIONS'  #@param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cARPh3t8ccl5"
   },
   "source": [
    "By calling the `describe_use_case_requirements` method we can view what datasets are required for this use_case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 724,
     "status": "ok",
     "timestamp": 1609878149396,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "5oZW86H6tUVR",
    "outputId": "73fc7782-a5f4-4320-aa3b-9bbc6e0bc0ea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>required</th>\n",
       "      <th>allowed_feature_mappings</th>\n",
       "      <th>allowed_nested_feature_mappings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USER_ITEM_INTERACTIONS</td>\n",
       "      <td>User-Item Interactions</td>\n",
       "      <td>This dataset corresponds to all the user-item interactions on your website or application. For example, all the actions (e.g. click, purchase, view) taken by a particular user on a particular item (e.g product, video. article) recorded as a time-based log.</td>\n",
       "      <td>True</td>\n",
       "      <td>{'ITEM_ID': {'description': 'This is the unique identifier of each item in your catalog. This is typically your product id, article id, or the video id.', 'allowed_feature_types': ['CATEGORICAL'], 'required': True}, 'USER_ID': {'description': 'This is a unique identifier of each user in your user base.', 'allowed_feature_types': ['CATEGORICAL'], 'required': True}, 'ACTION_TYPE': {'description': 'This is an optional column that specifies the type of action the user took. This could include any action that is specific to you (e.g., view, click, purchase, rating, comment, like, etc). You can always upload a dataset that has no action_type column if all the actions in the dataset are the same (e.g., a dataset of only purchases or clicks).', 'allowed_feature_types': ['CATEGORICAL'], 'required': False}, 'TIMESTAMP': {'description': 'The timestamp when a particular action occurred.', 'allowed_feature_types': ['TIMESTAMP'], 'required': False}, 'ACTION_WEIGHT': {'description': 'This is an optional column that specifies the weight of the action (e.g., video watch time, price of item purchased). This is used to optimize the the model to maximize actions with this value.', 'allowed_feature_types': ['NUMERICAL'], 'required': False}, 'IGNORE': {'description': 'Ignore this column in training', 'multiple': True, 'required': False}}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CATALOG_ATTRIBUTES</td>\n",
       "      <td>Catalog Attributes</td>\n",
       "      <td>This dataset corresponds to all the information you have in your catalog. If you want to recommend actions instead of items to users, you are welcome to upload an action catalog.</td>\n",
       "      <td>None</td>\n",
       "      <td>{'ITEM_ID': {'description': 'This is a unique identifier of each item in your catalog. This is typically your product id, article id, or video id.', 'allowed_feature_types': ['CATEGORICAL'], 'required': True}, 'PREDICTION_RESTRICT': {'description': 'This is an optional column that is used to restrict predictions to items matching a specific value of this column. If this is set, then the prediction api call will require that a includeFilter specifying a value for this column be included.', 'allowed_feature_types': ['CATEGORICAL'], 'required': False}, 'IGNORE': {'description': 'Ignore this column in training', 'multiple': True, 'required': False}}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USER_ATTRIBUTES</td>\n",
       "      <td>User Attributes</td>\n",
       "      <td>This dataset corresponds to all the attributes or meta-data that you have about your user base. Any user profile information will be relevant here.</td>\n",
       "      <td>None</td>\n",
       "      <td>{'USER_ID': {'description': 'The unique identifier for the user.', 'allowed_feature_types': ['CATEGORICAL'], 'required': True}, 'IGNORE': {'description': 'Ignore this column in training', 'multiple': True, 'required': False}}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dataset_type                    name  \\\n",
       "0  USER_ITEM_INTERACTIONS  User-Item Interactions   \n",
       "1      CATALOG_ATTRIBUTES      Catalog Attributes   \n",
       "2         USER_ATTRIBUTES         User Attributes   \n",
       "\n",
       "                                                                                                                                                                                                                                                        description  \\\n",
       "0  This dataset corresponds to all the user-item interactions on your website or application. For example, all the actions (e.g. click, purchase, view) taken by a particular user on a particular item (e.g product, video. article) recorded as a time-based log.   \n",
       "1                                                                                This dataset corresponds to all the information you have in your catalog. If you want to recommend actions instead of items to users, you are welcome to upload an action catalog.   \n",
       "2                                                                                                               This dataset corresponds to all the attributes or meta-data that you have about your user base. Any user profile information will be relevant here.   \n",
       "\n",
       "  required  \\\n",
       "0     True   \n",
       "1     None   \n",
       "2     None   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    allowed_feature_mappings  \\\n",
       "0  {'ITEM_ID': {'description': 'This is the unique identifier of each item in your catalog. This is typically your product id, article id, or the video id.', 'allowed_feature_types': ['CATEGORICAL'], 'required': True}, 'USER_ID': {'description': 'This is a unique identifier of each user in your user base.', 'allowed_feature_types': ['CATEGORICAL'], 'required': True}, 'ACTION_TYPE': {'description': 'This is an optional column that specifies the type of action the user took. This could include any action that is specific to you (e.g., view, click, purchase, rating, comment, like, etc). You can always upload a dataset that has no action_type column if all the actions in the dataset are the same (e.g., a dataset of only purchases or clicks).', 'allowed_feature_types': ['CATEGORICAL'], 'required': False}, 'TIMESTAMP': {'description': 'The timestamp when a particular action occurred.', 'allowed_feature_types': ['TIMESTAMP'], 'required': False}, 'ACTION_WEIGHT': {'description': 'This is an optional column that specifies the weight of the action (e.g., video watch time, price of item purchased). This is used to optimize the the model to maximize actions with this value.', 'allowed_feature_types': ['NUMERICAL'], 'required': False}, 'IGNORE': {'description': 'Ignore this column in training', 'multiple': True, 'required': False}}   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              {'ITEM_ID': {'description': 'This is a unique identifier of each item in your catalog. This is typically your product id, article id, or video id.', 'allowed_feature_types': ['CATEGORICAL'], 'required': True}, 'PREDICTION_RESTRICT': {'description': 'This is an optional column that is used to restrict predictions to items matching a specific value of this column. If this is set, then the prediction api call will require that a includeFilter specifying a value for this column be included.', 'allowed_feature_types': ['CATEGORICAL'], 'required': False}, 'IGNORE': {'description': 'Ignore this column in training', 'multiple': True, 'required': False}}   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          {'USER_ID': {'description': 'The unique identifier for the user.', 'allowed_feature_types': ['CATEGORICAL'], 'required': True}, 'IGNORE': {'description': 'Ignore this column in training', 'multiple': True, 'required': False}}   \n",
       "\n",
       "  allowed_nested_feature_mappings  \n",
       "0                            None  \n",
       "1                            None  \n",
       "2                            None  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requirements = client.describe_use_case_requirements(use_case)\n",
    "pd.DataFrame(requirement.to_dict() for requirement in requirements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kR_Zq0Aqceq0"
   },
   "source": [
    "Finally, let's create the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1547,
     "status": "ok",
     "timestamp": 1609881745309,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "ekTMnXyotWKg",
    "outputId": "43cc7efa-cbee-402d-82c9-2fb73101e8aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project_id': 'f4b4fc54',\n",
       " 'name': 'Movie Recommendations',\n",
       " 'use_case': 'USER_RECOMMENDATIONS',\n",
       " 'created_at': '2021-11-24T18:13:33+00:00',\n",
       " 'feature_groups_enabled': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_project = client.create_project(name='Movie Recommendations', use_case=use_case)\n",
    "recommendations_project.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8O41vBUQcgxN"
   },
   "source": [
    "## 2. Add Datasets to your Project\n",
    "\n",
    "Abacus.AI can read datasets directly from `AWS S3` or `Google Cloud Storage` buckets, otherwise you can also directly upload and store your datasets with Abacus.AI. For this notebook, we will have Abacus.AI read the datasets directly from a public S3 bucket's location.\n",
    "\n",
    "We are using three datasets for this notebook. We'll tell Abacus.AI how the datasets should be used when creating them by tagging each dataset with a special Abacus.AI **Dataset Type**.\n",
    "- [User Item Recommendations](https://s3.amazonaws.com//realityengines.exampledatasets/user_recommendations/user_movie_ratings.csv) (**USER_ITEM_INTERACTIONS**): \n",
    "This dataset contains information about multiple users' ratings of movies with specified IDs.\n",
    "- [Movie Attributes](https://s3.amazonaws.com//realityengines.exampledatasets/user_recommendations/movies_metadata.csv) (**CATALOG_ATTRIBUTES**): This dataset contains attributes about movies with specified IDs, such as each movie's name and genre.\n",
    "- [User Attributes](https://s3.amazonaws.com//realityengines.exampledatasets/user_recommendations/users_metadata.csv) (**USER_ATTRIBUTES**): This dataset contains information about users with specified IDs, such as their age, gender, occupation, and zip code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpofeV6ldWam"
   },
   "source": [
    "### Add the datasets to Abacus.AI\n",
    "\n",
    "First we'll use Pandas to preview the files, then add them to Abacus.AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 933,
     "status": "ok",
     "timestamp": 1609878157855,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "OK4QsHHdtmWg",
    "outputId": "554173ee-c229-481b-b7b5-dc1e1f5cc995"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "      <td>978302039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "      <td>978300719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575276</th>\n",
       "      <td>6040</td>\n",
       "      <td>1089</td>\n",
       "      <td>4</td>\n",
       "      <td>956704996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575277</th>\n",
       "      <td>6040</td>\n",
       "      <td>1094</td>\n",
       "      <td>5</td>\n",
       "      <td>956704887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575278</th>\n",
       "      <td>6040</td>\n",
       "      <td>562</td>\n",
       "      <td>5</td>\n",
       "      <td>956704746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575279</th>\n",
       "      <td>6040</td>\n",
       "      <td>1096</td>\n",
       "      <td>4</td>\n",
       "      <td>956715648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575280</th>\n",
       "      <td>6040</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "      <td>956715569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>575281 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  movie_id  rating  timestamp\n",
       "0             1      1193       5  978300760\n",
       "1             1      3408       4  978300275\n",
       "2             1      2355       5  978824291\n",
       "3             1      1287       5  978302039\n",
       "4             1      2804       5  978300719\n",
       "...         ...       ...     ...        ...\n",
       "575276     6040      1089       4  956704996\n",
       "575277     6040      1094       5  956704887\n",
       "575278     6040       562       5  956704746\n",
       "575279     6040      1096       4  956715648\n",
       "575280     6040      1097       4  956715569\n",
       "\n",
       "[575281 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('https://s3.amazonaws.com//abacusai.exampledatasets/user_recommendations/user_movie_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 605,
     "status": "ok",
     "timestamp": 1609878159734,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "BIPrCtrqtoWy",
    "outputId": "b6d261b1-9cb0-4789-ca7b-59d61cc9bf82"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3878</th>\n",
       "      <td>3948</td>\n",
       "      <td>Meet the Parents (2000)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879</th>\n",
       "      <td>3949</td>\n",
       "      <td>Requiem for a Dream (2000)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880</th>\n",
       "      <td>3950</td>\n",
       "      <td>Tigerland (2000)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>3951</td>\n",
       "      <td>Two Family House (2000)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3882</th>\n",
       "      <td>3952</td>\n",
       "      <td>Contender, The (2000)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3883 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movie_id                               movie  \\\n",
       "0            1                    Toy Story (1995)   \n",
       "1            2                      Jumanji (1995)   \n",
       "2            3             Grumpier Old Men (1995)   \n",
       "3            4            Waiting to Exhale (1995)   \n",
       "4            5  Father of the Bride Part II (1995)   \n",
       "...        ...                                 ...   \n",
       "3878      3948             Meet the Parents (2000)   \n",
       "3879      3949          Requiem for a Dream (2000)   \n",
       "3880      3950                    Tigerland (2000)   \n",
       "3881      3951             Two Family House (2000)   \n",
       "3882      3952               Contender, The (2000)   \n",
       "\n",
       "                            genres  \n",
       "0      Animation|Children's|Comedy  \n",
       "1     Adventure|Children's|Fantasy  \n",
       "2                   Comedy|Romance  \n",
       "3                     Comedy|Drama  \n",
       "4                           Comedy  \n",
       "...                            ...  \n",
       "3878                        Comedy  \n",
       "3879                         Drama  \n",
       "3880                         Drama  \n",
       "3881                         Drama  \n",
       "3882                Drama|Thriller  \n",
       "\n",
       "[3883 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('https://s3.amazonaws.com//abacusai.exampledatasets/user_recommendations/movies_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 624,
     "status": "ok",
     "timestamp": 1609878162053,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "qHf00pKHtohx",
    "outputId": "e3ee8477-d9f8-45ce-8202-ccaa7f6d8458"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>Under 18</td>\n",
       "      <td>K-12 student</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56+</td>\n",
       "      <td>self-employed</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25-34</td>\n",
       "      <td>scientist</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45-49</td>\n",
       "      <td>executive/managerial</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25-34</td>\n",
       "      <td>writer</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>6036</td>\n",
       "      <td>F</td>\n",
       "      <td>25-34</td>\n",
       "      <td>scientist</td>\n",
       "      <td>32603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>6037</td>\n",
       "      <td>F</td>\n",
       "      <td>45-49</td>\n",
       "      <td>academic/educator</td>\n",
       "      <td>76006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>6038</td>\n",
       "      <td>F</td>\n",
       "      <td>56+</td>\n",
       "      <td>academic/educator</td>\n",
       "      <td>14706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>6039</td>\n",
       "      <td>F</td>\n",
       "      <td>45-49</td>\n",
       "      <td>other</td>\n",
       "      <td>01060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6040</td>\n",
       "      <td>M</td>\n",
       "      <td>25-34</td>\n",
       "      <td>doctor/health care</td>\n",
       "      <td>11106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6040 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id gender       age            occupation zip_code\n",
       "0           1      F  Under 18          K-12 student    48067\n",
       "1           2      M       56+         self-employed    70072\n",
       "2           3      M     25-34             scientist    55117\n",
       "3           4      M     45-49  executive/managerial    02460\n",
       "4           5      M     25-34                writer    55455\n",
       "...       ...    ...       ...                   ...      ...\n",
       "6035     6036      F     25-34             scientist    32603\n",
       "6036     6037      F     45-49     academic/educator    76006\n",
       "6037     6038      F       56+     academic/educator    14706\n",
       "6038     6039      F     45-49                 other    01060\n",
       "6039     6040      M     25-34    doctor/health care    11106\n",
       "\n",
       "[6040 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('https://s3.amazonaws.com//abacusai.exampledatasets/user_recommendations/users_metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7g0ZLTTcmJj"
   },
   "source": [
    "Using the Create Dataset API, we can tell Abacus.AI the public S3 URI of where to find the datasets. We will also give each dataset a Refresh Schedule, which tells Abacus.AI when it should refresh the dataset (take an updated/latest copy of the dataset).\n",
    "\n",
    "The Refresh Schedule is given with a cron string. For example, when entering \"0 12 * * *\", the dataset is going to be re-read from the s3 at 12pm UTC, so that no update are missed.\n",
    "\n",
    "If you're unfamiliar with Cron Syntax, Crontab Guru can help translate the syntax back into natural language: [https://crontab.guru/#0_12_\\*_\\*_\\*](https://crontab.guru/#0_12_*_*_*)\n",
    "\n",
    "**Note: This cron string will be evaluated in UTC time zone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 2515,
     "status": "ok",
     "timestamp": 1609881753892,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "yjKasrIStwpm"
   },
   "outputs": [],
   "source": [
    "user_item_dataset = client.create_dataset_from_file_connector(\n",
    "    name='User Item Recommendations',\n",
    "    table_name='User_Item_Recommendations',\n",
    "    location='s3://abacusai.exampledatasets/user_recommendations/user_movie_ratings.csv',\n",
    "    refresh_schedule='0 12 * * *'\n",
    ")\n",
    "\n",
    "movie_attributes_dataset = client.create_dataset_from_file_connector(\n",
    "    name='Movie Attributes',\n",
    "    table_name='Movie_Attributes',\n",
    "    location='s3://abacusai.exampledatasets/user_recommendations/movies_metadata.csv',\n",
    "    refresh_schedule='0 12 * * *'\n",
    ")\n",
    "\n",
    "user_attributes_dataset = client.create_dataset_from_file_connector(\n",
    "    name='User Attributes',\n",
    "    table_name='User_Attributes',\n",
    "    location='s3://abacusai.exampledatasets/user_recommendations/users_metadata.csv',\n",
    "    refresh_schedule='0 12 * * *'\n",
    ")\n",
    "\n",
    "datasets = [user_item_dataset, movie_attributes_dataset, user_attributes_dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Feature Groups and add them to your Project\n",
    "\n",
    "Datasets are created at the organization level and can be used to create feature groups as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group = client.create_feature_group(table_name='personalized_recommendations',sql='SELECT * from User_Item_Recommendations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DANKeBcwdZPy"
   },
   "source": [
    "Adding Feature Group to the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.add_feature_group_to_project(feature_group_id=feature_group.feature_group_id,project_id = recommendations_project.project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRjRmMMRdcXs"
   },
   "source": [
    "Setting the Feature Group type according to the use case requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set_feature_group_type(feature_group_id=feature_group.feature_group_id, project_id = recommendations_project.project_id, feature_group_type= \"USER_ITEM_INTERACTIONS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check current Feature Group schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Feature(name='user_id',\n",
       "   select_clause=None,\n",
       "   feature_mapping=None,\n",
       "   source_table='User_Item_Recommendations',\n",
       "   original_name=None,\n",
       "   using_clause=None,\n",
       "   order_clause=None,\n",
       "   where_clause=None,\n",
       "   feature_type='CATEGORICAL',\n",
       "   data_type='STRING',\n",
       "   columns=None,\n",
       "   point_in_time_info=None),\n",
       " Feature(name='movie_id',\n",
       "   select_clause=None,\n",
       "   feature_mapping=None,\n",
       "   source_table='User_Item_Recommendations',\n",
       "   original_name=None,\n",
       "   using_clause=None,\n",
       "   order_clause=None,\n",
       "   where_clause=None,\n",
       "   feature_type='CATEGORICAL',\n",
       "   data_type='STRING',\n",
       "   columns=None,\n",
       "   point_in_time_info=None),\n",
       " Feature(name='rating',\n",
       "   select_clause=None,\n",
       "   feature_mapping=None,\n",
       "   source_table='User_Item_Recommendations',\n",
       "   original_name=None,\n",
       "   using_clause=None,\n",
       "   order_clause=None,\n",
       "   where_clause=None,\n",
       "   feature_type='CATEGORICAL',\n",
       "   data_type='STRING',\n",
       "   columns=None,\n",
       "   point_in_time_info=None),\n",
       " Feature(name='timestamp',\n",
       "   select_clause=None,\n",
       "   feature_mapping=None,\n",
       "   source_table='User_Item_Recommendations',\n",
       "   original_name=None,\n",
       "   using_clause=None,\n",
       "   order_clause=None,\n",
       "   where_clause=None,\n",
       "   feature_type='TIMESTAMP',\n",
       "   data_type='DATETIME',\n",
       "   columns=None,\n",
       "   point_in_time_info=None)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_feature_group_schema(feature_group_id=feature_group.feature_group_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each **Use Case**, there are special **Column Mappings** that must be applied to a column to fulfill use case requirements. We can find the list of available **Column Mappings** by calling the *Describe Use Case Requirements* API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 113983,
     "status": "ok",
     "timestamp": 1609881875744,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "fr3TVpOUuXZz",
    "outputId": "92660c44-cf8d-4389-c727-5735972e5aa9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ITEM_ID': {'description': 'This is the unique identifier of each item in your catalog. This is typically your product id, article id, or the video id.',\n",
       "  'allowed_feature_types': ['CATEGORICAL'],\n",
       "  'required': True},\n",
       " 'USER_ID': {'description': 'This is a unique identifier of each user in your user base.',\n",
       "  'allowed_feature_types': ['CATEGORICAL'],\n",
       "  'required': True},\n",
       " 'ACTION_TYPE': {'description': 'This is an optional column that specifies the type of action the user took. This could include any action that is specific to you (e.g., view, click, purchase, rating, comment, like, etc). You can always upload a dataset that has no action_type column if all the actions in the dataset are the same (e.g., a dataset of only purchases or clicks).',\n",
       "  'allowed_feature_types': ['CATEGORICAL'],\n",
       "  'required': False},\n",
       " 'TIMESTAMP': {'description': 'The timestamp when a particular action occurred.',\n",
       "  'allowed_feature_types': ['TIMESTAMP'],\n",
       "  'required': False},\n",
       " 'ACTION_WEIGHT': {'description': 'This is an optional column that specifies the weight of the action (e.g., video watch time, price of item purchased). This is used to optimize the the model to maximize actions with this value.',\n",
       "  'allowed_feature_types': ['NUMERICAL'],\n",
       "  'required': False},\n",
       " 'IGNORE': {'description': 'Ignore this column in training',\n",
       "  'multiple': True,\n",
       "  'required': False}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.describe_use_case_requirements(use_case)[0].allowed_feature_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Feature(name='user_id',\n",
       "   select_clause=None,\n",
       "   feature_mapping='USER_ID',\n",
       "   source_table='User_Item_Recommendations',\n",
       "   original_name=None,\n",
       "   using_clause=None,\n",
       "   order_clause=None,\n",
       "   where_clause=None,\n",
       "   feature_type='CATEGORICAL',\n",
       "   data_type='STRING',\n",
       "   columns=None,\n",
       "   point_in_time_info=None),\n",
       " Feature(name='movie_id',\n",
       "   select_clause=None,\n",
       "   feature_mapping='ITEM_ID',\n",
       "   source_table='User_Item_Recommendations',\n",
       "   original_name=None,\n",
       "   using_clause=None,\n",
       "   order_clause=None,\n",
       "   where_clause=None,\n",
       "   feature_type='CATEGORICAL',\n",
       "   data_type='STRING',\n",
       "   columns=None,\n",
       "   point_in_time_info=None),\n",
       " Feature(name='rating',\n",
       "   select_clause=None,\n",
       "   feature_mapping=None,\n",
       "   source_table='User_Item_Recommendations',\n",
       "   original_name=None,\n",
       "   using_clause=None,\n",
       "   order_clause=None,\n",
       "   where_clause=None,\n",
       "   feature_type='CATEGORICAL',\n",
       "   data_type='STRING',\n",
       "   columns=None,\n",
       "   point_in_time_info=None),\n",
       " Feature(name='timestamp',\n",
       "   select_clause=None,\n",
       "   feature_mapping='TIMESTAMP',\n",
       "   source_table='User_Item_Recommendations',\n",
       "   original_name=None,\n",
       "   using_clause=None,\n",
       "   order_clause=None,\n",
       "   where_clause=None,\n",
       "   feature_type='TIMESTAMP',\n",
       "   data_type='DATETIME',\n",
       "   columns=None,\n",
       "   point_in_time_info=None)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.set_feature_mapping(project_id = recommendations_project.project_id,feature_group_id= feature_group.feature_group_id, feature_name='movie_id',feature_mapping='ITEM_ID')\n",
    "client.set_feature_mapping(project_id = recommendations_project.project_id,feature_group_id= feature_group.feature_group_id, feature_name='user_id',feature_mapping='USER_ID')\n",
    "client.set_feature_mapping(project_id = recommendations_project.project_id,feature_group_id= feature_group.feature_group_id, feature_name='timestamp',feature_mapping='TIMESTAMP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each required Feature Group Type within the use case, you must assign the Feature group to be used for training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.use_feature_group_for_training(project_id=recommendations_project.project_id, feature_group_id=feature_group.feature_group_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've our feature groups assigned, we're almost ready to train a model!\n",
    "\n",
    "To be sure that our project is ready to go, let's call project.validate to confirm that all the project requirements have been met:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProjectValidation(valid=True,\n",
       "  dataset_errors=[],\n",
       "  column_hints={})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_project.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWvYvPEmdfg7"
   },
   "source": [
    "## 4. Train a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3grtGDidiNT"
   },
   "source": [
    "For each **Use Case**, Abacus.AI has a bunch of options for training. We can call the `get_training_config_options` API to see the available options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108423,
     "status": "ok",
     "timestamp": 1609881878683,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "sZZ0LDQ9vBsb",
    "outputId": "deb98392-bd6b-4a64-e91a-af37edaad729"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TrainingConfigOptions(name='TEST_SPLIT',\n",
       "   data_type='INTEGER',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'range': [5, 20]},\n",
       "   description='Percent of dataset to use for test data. We support using a range between 6% to 20% of your dataset to use as test data.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='DROPOUT_RATE',\n",
       "   data_type='INTEGER',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'range': [0, 90]},\n",
       "   description='Dropout percentage rate.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='BATCH_SIZE',\n",
       "   data_type='ENUM',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'values': [8, 16, 32, 64, 128, 256, 384, 512, 740, 1024]},\n",
       "   description='Batch size.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='SKIP_HISTORY_FILTERING',\n",
       "   data_type='BOOLEAN',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=False,\n",
       "   options=None,\n",
       "   description='Do not remove items which have past interactions from recommendations.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='MAX_HISTORY_LENGTH',\n",
       "   data_type='INTEGER',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'range': [0, 200]},\n",
       "   description='Maximum length of user-item history to include user in training examples.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='USE_ITEM_ATTRIBUTE_BUCKETING',\n",
       "   data_type='BOOLEAN',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options=None,\n",
       "   description='Prefer recommending items which have attribute similarity. Useful when we have natural item categories which are related, like e-commerce categories.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='UNORDERED_HISTORY',\n",
       "   data_type='BOOLEAN',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=False,\n",
       "   options=None,\n",
       "   description='Order of user item interactions is not important.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='MAX_USER_HISTORY_LEN_PERCENTILE',\n",
       "   data_type='INTEGER',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'range': [95, 100]},\n",
       "   description='Filter out users with history length above this percentile.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='DOWNSAMPLE_ITEM_POPULARITY_PERCENTILE',\n",
       "   data_type='DECIMAL',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'range': [0.1, 1.0]},\n",
       "   description='Downsample items more popular than this percentile.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='RECENT_DAYS_FOR_TRAINING',\n",
       "   data_type='INTEGER',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'range': [1, 1000]},\n",
       "   description='Limit training data to a certain latest number of days.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='TRAINING_START_DATE',\n",
       "   data_type='DATETIME',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options=None,\n",
       "   description='Only consider training interaction data after this date. Specified in the timezone of the dataset.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='TEST_ON_USER_SPLIT',\n",
       "   data_type='BOOLEAN',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=False,\n",
       "   options=None,\n",
       "   description='Use user splits instead of using time splits, when validating and testing the model.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='TRAINING_CANDIDATE_ITEMS_LIMIT',\n",
       "   data_type='INTEGER',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'range': [1000, 150000]},\n",
       "   description='Limit training data to these many \"best performing\" items. We use target events and weights to calculate it',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='MIN_INTERACTIONS',\n",
       "   data_type='INTEGER',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'range': [0, 10000]},\n",
       "   description='Select candidate items with at least this many interactions.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='MIN_TARGET_INTERACTIONS',\n",
       "   data_type='INTEGER',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'range': [0, 10000]},\n",
       "   description='Select candidate items with at least this many target interactions.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='CANDIDATE_SELECTION_TARGET_RATE_SCORING',\n",
       "   data_type='BOOLEAN',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=False,\n",
       "   options=None,\n",
       "   description='Use the rate of target events to select the candidates instead of the total score. Use this to make sure new items are considered in the selection',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='CANDIDATE_SELECTION_MAX_OTHER_EVENT_RATE',\n",
       "   data_type='DECIMAL',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options=None,\n",
       "   description='To prevent selecting outliers, cap the rate of target events (which are not part of session events) for candidate items to not exceed this value',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='SEARCH_QUERY_COLUMN',\n",
       "   data_type='ENUM',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'values': ['rating']},\n",
       "   description='Column which specifies a search query term that will be used for personalization.',\n",
       "   required=None,\n",
       "   last_model_value=None),\n",
       " TrainingConfigOptions(name='EXPLORE_LOOKBACK_HOURS',\n",
       "   data_type='DECIMAL',\n",
       "   value_type=None,\n",
       "   value_options=None,\n",
       "   value=None,\n",
       "   default=None,\n",
       "   options={'range': [1, 168]},\n",
       "   description='Number of hours since creation time that an item is eligiblefor explore fraction.',\n",
       "   required=None,\n",
       "   last_model_value=None)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_config_options = recommendations_project.get_training_config_options()\n",
    "training_config_options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqpRkZ9sTqzS"
   },
   "source": [
    "To have a nice display:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 106309,
     "status": "ok",
     "timestamp": 1609881878686,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "d5inDZc4TwPD",
    "outputId": "a8a8d465-f395-49d9-e4ba-3393170ceea5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>data_type</th>\n",
       "      <th>value_type</th>\n",
       "      <th>value_options</th>\n",
       "      <th>value</th>\n",
       "      <th>default</th>\n",
       "      <th>options</th>\n",
       "      <th>description</th>\n",
       "      <th>required</th>\n",
       "      <th>last_model_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_SPLIT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'range': [5, 20]}</td>\n",
       "      <td>Percent of dataset to use for test data. We support using a range between 6% to 20% of your dataset to use as test data.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DROPOUT_RATE</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'range': [0, 90]}</td>\n",
       "      <td>Dropout percentage rate.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BATCH_SIZE</td>\n",
       "      <td>ENUM</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'values': [8, 16, 32, 64, 128, 256, 384, 512, 740, 1024]}</td>\n",
       "      <td>Batch size.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SKIP_HISTORY_FILTERING</td>\n",
       "      <td>BOOLEAN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Do not remove items which have past interactions from recommendations.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAX_HISTORY_LENGTH</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'range': [0, 200]}</td>\n",
       "      <td>Maximum length of user-item history to include user in training examples.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>USE_ITEM_ATTRIBUTE_BUCKETING</td>\n",
       "      <td>BOOLEAN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Prefer recommending items which have attribute similarity. Useful when we have natural item categories which are related, like e-commerce categories.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UNORDERED_HISTORY</td>\n",
       "      <td>BOOLEAN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Order of user item interactions is not important.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MAX_USER_HISTORY_LEN_PERCENTILE</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'range': [95, 100]}</td>\n",
       "      <td>Filter out users with history length above this percentile.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DOWNSAMPLE_ITEM_POPULARITY_PERCENTILE</td>\n",
       "      <td>DECIMAL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'range': [0.1, 1.0]}</td>\n",
       "      <td>Downsample items more popular than this percentile.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RECENT_DAYS_FOR_TRAINING</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'range': [1, 1000]}</td>\n",
       "      <td>Limit training data to a certain latest number of days.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TRAINING_START_DATE</td>\n",
       "      <td>DATETIME</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Only consider training interaction data after this date. Specified in the timezone of the dataset.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TEST_ON_USER_SPLIT</td>\n",
       "      <td>BOOLEAN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Use user splits instead of using time splits, when validating and testing the model.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TRAINING_CANDIDATE_ITEMS_LIMIT</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'range': [1000, 150000]}</td>\n",
       "      <td>Limit training data to these many \"best performing\" items. We use target events and weights to calculate it</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MIN_INTERACTIONS</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'range': [0, 10000]}</td>\n",
       "      <td>Select candidate items with at least this many interactions.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MIN_TARGET_INTERACTIONS</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'range': [0, 10000]}</td>\n",
       "      <td>Select candidate items with at least this many target interactions.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CANDIDATE_SELECTION_TARGET_RATE_SCORING</td>\n",
       "      <td>BOOLEAN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Use the rate of target events to select the candidates instead of the total score. Use this to make sure new items are considered in the selection</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CANDIDATE_SELECTION_MAX_OTHER_EVENT_RATE</td>\n",
       "      <td>DECIMAL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>To prevent selecting outliers, cap the rate of target events (which are not part of session events) for candidate items to not exceed this value</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SEARCH_QUERY_COLUMN</td>\n",
       "      <td>ENUM</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'values': ['rating']}</td>\n",
       "      <td>Column which specifies a search query term that will be used for personalization.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EXPLORE_LOOKBACK_HOURS</td>\n",
       "      <td>DECIMAL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'range': [1, 168]}</td>\n",
       "      <td>Number of hours since creation time that an item is eligiblefor explore fraction.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        name data_type value_type  \\\n",
       "0                                 TEST_SPLIT   INTEGER       None   \n",
       "1                               DROPOUT_RATE   INTEGER       None   \n",
       "2                                 BATCH_SIZE      ENUM       None   \n",
       "3                     SKIP_HISTORY_FILTERING   BOOLEAN       None   \n",
       "4                         MAX_HISTORY_LENGTH   INTEGER       None   \n",
       "5               USE_ITEM_ATTRIBUTE_BUCKETING   BOOLEAN       None   \n",
       "6                          UNORDERED_HISTORY   BOOLEAN       None   \n",
       "7            MAX_USER_HISTORY_LEN_PERCENTILE   INTEGER       None   \n",
       "8      DOWNSAMPLE_ITEM_POPULARITY_PERCENTILE   DECIMAL       None   \n",
       "9                   RECENT_DAYS_FOR_TRAINING   INTEGER       None   \n",
       "10                       TRAINING_START_DATE  DATETIME       None   \n",
       "11                        TEST_ON_USER_SPLIT   BOOLEAN       None   \n",
       "12            TRAINING_CANDIDATE_ITEMS_LIMIT   INTEGER       None   \n",
       "13                          MIN_INTERACTIONS   INTEGER       None   \n",
       "14                   MIN_TARGET_INTERACTIONS   INTEGER       None   \n",
       "15   CANDIDATE_SELECTION_TARGET_RATE_SCORING   BOOLEAN       None   \n",
       "16  CANDIDATE_SELECTION_MAX_OTHER_EVENT_RATE   DECIMAL       None   \n",
       "17                       SEARCH_QUERY_COLUMN      ENUM       None   \n",
       "18                    EXPLORE_LOOKBACK_HOURS   DECIMAL       None   \n",
       "\n",
       "   value_options value default  \\\n",
       "0           None  None    None   \n",
       "1           None  None    None   \n",
       "2           None  None    None   \n",
       "3           None  None   False   \n",
       "4           None  None    None   \n",
       "5           None  None    None   \n",
       "6           None  None   False   \n",
       "7           None  None    None   \n",
       "8           None  None    None   \n",
       "9           None  None    None   \n",
       "10          None  None    None   \n",
       "11          None  None   False   \n",
       "12          None  None    None   \n",
       "13          None  None    None   \n",
       "14          None  None    None   \n",
       "15          None  None   False   \n",
       "16          None  None    None   \n",
       "17          None  None    None   \n",
       "18          None  None    None   \n",
       "\n",
       "                                                       options  \\\n",
       "0                                           {'range': [5, 20]}   \n",
       "1                                           {'range': [0, 90]}   \n",
       "2   {'values': [8, 16, 32, 64, 128, 256, 384, 512, 740, 1024]}   \n",
       "3                                                         None   \n",
       "4                                          {'range': [0, 200]}   \n",
       "5                                                         None   \n",
       "6                                                         None   \n",
       "7                                         {'range': [95, 100]}   \n",
       "8                                        {'range': [0.1, 1.0]}   \n",
       "9                                         {'range': [1, 1000]}   \n",
       "10                                                        None   \n",
       "11                                                        None   \n",
       "12                                   {'range': [1000, 150000]}   \n",
       "13                                       {'range': [0, 10000]}   \n",
       "14                                       {'range': [0, 10000]}   \n",
       "15                                                        None   \n",
       "16                                                        None   \n",
       "17                                      {'values': ['rating']}   \n",
       "18                                         {'range': [1, 168]}   \n",
       "\n",
       "                                                                                                                                              description  \\\n",
       "0                                Percent of dataset to use for test data. We support using a range between 6% to 20% of your dataset to use as test data.   \n",
       "1                                                                                                                                Dropout percentage rate.   \n",
       "2                                                                                                                                             Batch size.   \n",
       "3                                                                                  Do not remove items which have past interactions from recommendations.   \n",
       "4                                                                               Maximum length of user-item history to include user in training examples.   \n",
       "5   Prefer recommending items which have attribute similarity. Useful when we have natural item categories which are related, like e-commerce categories.   \n",
       "6                                                                                                       Order of user item interactions is not important.   \n",
       "7                                                                                             Filter out users with history length above this percentile.   \n",
       "8                                                                                                     Downsample items more popular than this percentile.   \n",
       "9                                                                                                 Limit training data to a certain latest number of days.   \n",
       "10                                                     Only consider training interaction data after this date. Specified in the timezone of the dataset.   \n",
       "11                                                                   Use user splits instead of using time splits, when validating and testing the model.   \n",
       "12                                            Limit training data to these many \"best performing\" items. We use target events and weights to calculate it   \n",
       "13                                                                                           Select candidate items with at least this many interactions.   \n",
       "14                                                                                    Select candidate items with at least this many target interactions.   \n",
       "15     Use the rate of target events to select the candidates instead of the total score. Use this to make sure new items are considered in the selection   \n",
       "16       To prevent selecting outliers, cap the rate of target events (which are not part of session events) for candidate items to not exceed this value   \n",
       "17                                                                      Column which specifies a search query term that will be used for personalization.   \n",
       "18                                                                      Number of hours since creation time that an item is eligiblefor explore fraction.   \n",
       "\n",
       "   required last_model_value  \n",
       "0      None             None  \n",
       "1      None             None  \n",
       "2      None             None  \n",
       "3      None             None  \n",
       "4      None             None  \n",
       "5      None             None  \n",
       "6      None             None  \n",
       "7      None             None  \n",
       "8      None             None  \n",
       "9      None             None  \n",
       "10     None             None  \n",
       "11     None             None  \n",
       "12     None             None  \n",
       "13     None             None  \n",
       "14     None             None  \n",
       "15     None             None  \n",
       "16     None             None  \n",
       "17     None             None  \n",
       "18     None             None  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(training_config_option.to_dict() for training_config_option in training_config_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjU_ouvAdj67"
   },
   "source": [
    "In this notebook, we'll just train with the default options, but definitely feel free to experiment, especially if you have familiarity with Machine Learning (See the description of the parameters [here](https://abacus.ai/app/help/useCases/user_recommendations/training))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 94722,
     "status": "ok",
     "timestamp": 1609881878687,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "A7ww-YurUhN6"
   },
   "outputs": [],
   "source": [
    "training_config = {\n",
    "    'BATCH_SIZE': None,\n",
    "    'DOWNSAMPLE_ITEM_POPULARITY_PERCENTILE': None,\n",
    "    'DROPOUT_RATE': None,\n",
    "    'EXCLUDE_TIME_FEATURES': None,\n",
    "    'IGNORE_ACTION_WEIGHT_COLUMN': None,\n",
    "    'MAX_HISTORY_LEN': None,\n",
    "    'MAX_USER_HISTORY_LEN_PERCENTILE': None,\n",
    "    'RECENT_DAYS_FOR_TRAINING': None,\n",
    "    'RERANKING_PERSONALIZATION_FACTOR': None,\n",
    "    'SEARCH_QUERY_COLUMN': None,\n",
    "    'SKIP_HISTORY_FILTERING': False,\n",
    "    'TARGET_EVENT_WEIGHTS': None,\n",
    "    'TEST_ON_USER_SPLIT': False,\n",
    "    'TEST_SPLIT': None,\n",
    "    'TRAINING_START_DATE': None,\n",
    "    'UNORDERED_HISTORY': False\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1500,
     "status": "ok",
     "timestamp": 1609881880219,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "MhbOMNj_vxEr",
    "outputId": "9748cb96-6401-4f55-fa20-78da255ab564"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Movie Recommendations Model',\n",
       " 'model_id': 'd7db57ac2',\n",
       " 'model_config': {'MAX_HISTORY_LEN': None,\n",
       "  'TARGET_EVENT_WEIGHTS': None,\n",
       "  'EXCLUDE_TIME_FEATURES': None,\n",
       "  'IGNORE_ACTION_WEIGHT_COLUMN': None,\n",
       "  'RERANKING_PERSONALIZATION_FACTOR': None},\n",
       " 'created_at': '2021-11-24T18:52:04+00:00',\n",
       " 'project_id': 'f4b4fc54',\n",
       " 'shared': False,\n",
       " 'shared_at': None,\n",
       " 'train_function_name': None,\n",
       " 'predict_function_name': None,\n",
       " 'training_input_tables': None,\n",
       " 'source_code': None,\n",
       " 'location': None,\n",
       " 'refresh_schedules': None,\n",
       " 'latest_model_version': {'model_version': '137693df6c',\n",
       "  'status': 'PENDING',\n",
       "  'model_id': 'd7db57ac2',\n",
       "  'model_config': {'MAX_HISTORY_LEN': None,\n",
       "   'TARGET_EVENT_WEIGHTS': None,\n",
       "   'EXCLUDE_TIME_FEATURES': None,\n",
       "   'IGNORE_ACTION_WEIGHT_COLUMN': None,\n",
       "   'RERANKING_PERSONALIZATION_FACTOR': None},\n",
       "  'training_started_at': None,\n",
       "  'training_completed_at': None,\n",
       "  'dataset_versions': None,\n",
       "  'error': None,\n",
       "  'pending_deployment_ids': None,\n",
       "  'failed_deployment_ids': None}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_model = recommendations_project.train_model(training_config=training_config)\n",
    "recommendations_model.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "529oNyl-dl3Z"
   },
   "source": [
    "After we start training the model, we can call this blocking call that routinely checks the status of the model until it is trained and evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "eJ2BtkogwIM2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(name='Movie Recommendations Model',\n",
       "  model_id='d7db57ac2',\n",
       "  model_config={'MAX_HISTORY_LEN': None, 'TARGET_EVENT_WEIGHTS': None, 'EXCLUDE_TIME_FEATURES': None, 'IGNORE_ACTION_WEIGHT_COLUMN': None, 'RERANKING_PERSONALIZATION_FACTOR': None},\n",
       "  created_at='2021-11-24T18:52:04+00:00',\n",
       "  project_id='f4b4fc54',\n",
       "  shared=False,\n",
       "  shared_at=None,\n",
       "  train_function_name=None,\n",
       "  predict_function_name=None,\n",
       "  training_input_tables=None,\n",
       "  source_code=None,\n",
       "  location=None,\n",
       "  refresh_schedules=None,\n",
       "  latest_model_version=ModelVersion(model_version='137693df6c',\n",
       "  status='COMPLETE',\n",
       "  model_id='d7db57ac2',\n",
       "  model_config={'MAX_HISTORY_LEN': None, 'TARGET_EVENT_WEIGHTS': None, 'EXCLUDE_TIME_FEATURES': None, 'IGNORE_ACTION_WEIGHT_COLUMN': None, 'RERANKING_PERSONALIZATION_FACTOR': None},\n",
       "  training_started_at='2021-11-24T18:53:59+00:00',\n",
       "  training_completed_at='2021-11-24T19:48:22+00:00',\n",
       "  dataset_versions=['6134b4244', '49ec355a8'],\n",
       "  error=None,\n",
       "  pending_deployment_ids=[],\n",
       "  failed_deployment_ids=[]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_model.wait_for_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0mIg2VHdnfA"
   },
   "source": [
    "## **(Checkpoint)**\n",
    "Training can take an hour or two to complete, but we encourage you to run the remaining calls on your own time. If your page times out or you hit refresh, you can restore your progress in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 152845,
     "status": "aborted",
     "timestamp": 1609881728395,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "hX9kkcnodpxG"
   },
   "outputs": [],
   "source": [
    "!pip install abacusai\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "api_key = ''  #@param {type: \"string\"}\n",
    "from abacusai import ApiClient\n",
    "client = ApiClient(api_key) \n",
    "recommendations_project = next(project for project in client.list_projects() if project.name == 'Movie Recommendations')\n",
    "recommendations_model = recommendations_project.list_models()[-1]\n",
    "recommendations_model.wait_for_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBK2e1WNd6L3"
   },
   "source": [
    "## Evaluate your Model Metrics\n",
    "\n",
    "After your model is done training you can inspect the model's quality by reviewing the model's metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 125877,
     "status": "aborted",
     "timestamp": 1609881728399,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "0612612IwJ8H"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_id': 'd7db57ac2',\n",
       " 'model_version': '137693df6c',\n",
       " 'metrics': {'ndcg': 0.330879625622261,\n",
       "  'ndcg@5': 0.24688789200373065,\n",
       "  'ndcg@10': 0.28277192204812096,\n",
       "  'map': 0.061221039683096536,\n",
       "  'map@5': 0.08421448087431693,\n",
       "  'map@10': 0.06970096965622921,\n",
       "  'mrr': 0.24470498577438823,\n",
       "  'personalization@10': 0.966502239137158,\n",
       "  'coverage': 0.4511746391168978},\n",
       " 'baseline_metrics': None,\n",
       " 'target_column': None}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_model.get_metrics().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WP1MNip0d7xM"
   },
   "source": [
    "To get a better understanding on what these metrics mean, visit our [documentation](https://abacus.ai/app/help/useCases/USER_RECOMMENDATIONS/training) page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xc5YAK8veBt1"
   },
   "source": [
    "## 5. Deploy Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhNqQGB0eDky"
   },
   "source": [
    "After the model has been trained, we need to deploy the model to be able to start making predictions. Deploying a model will reserve cloud resources to host the model for Realtime and/or batch predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 123824,
     "status": "aborted",
     "timestamp": 1609881728402,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "lS1XcyafwLl_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Deployment(deployment_id='13b0891610',\n",
       "  name='Personalized Recommendations Deployment',\n",
       "  status='ACTIVE',\n",
       "  description='',\n",
       "  deployed_at='2021-11-24T19:54:19+00:00',\n",
       "  created_at='2021-11-24T19:53:50+00:00',\n",
       "  project_id='f4b4fc54',\n",
       "  model_id='d7db57ac2',\n",
       "  model_version='137693df6c',\n",
       "  feature_group_id=None,\n",
       "  feature_group_version=None,\n",
       "  calls_per_second=5,\n",
       "  auto_deploy=True,\n",
       "  regions=[{'name': 'Us East 1', 'value': 'us-east-1'}],\n",
       "  error=None,\n",
       "  refresh_schedules=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_deployment = client.create_deployment(name='Personalized Recommendations Deployment',model_id=recommendations_model.model_id)\n",
    "recommendations_deployment.wait_for_deployment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4TUE2eveFDl"
   },
   "source": [
    "After the model is deployed, we need to create a deployment token for authenticating prediction requests. This token is only authorized to predict on deployments in this project, so it's safe to embed this token inside of a user-facing application or website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 121920,
     "status": "aborted",
     "timestamp": 1609881728403,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "AZHiO7jywTed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'070add66f05f4a7e9aceaa40e0b4a554'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_token = recommendations_project.create_deployment_token().deployment_token\n",
    "deployment_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzFpIsJ_eGmk"
   },
   "source": [
    "## 6. Make Predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-la9sapteIEy"
   },
   "source": [
    "Now that you have an active deployment and a deployment token to authenticate requests, you can make the `get_recommendations` API call below.\n",
    "\n",
    "To see a full description of the prediction API parameters, visit our [documentation](https://abacus.ai/app/help/useCases/USER_RECOMMENDATIONS/predictions) page. \n",
    "\n",
    "NB: The REST API keywords described in the documentation use the CamelCase word convention while the Python API one below use the snake case convention, see [here](https://medium.com/better-programming/string-case-styles-camel-pascal-snake-and-kebab-case-981407998841) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQ3wmT97WHBY"
   },
   "source": [
    "For the purpose of data visualization, we store the source file content in Pandas' dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 118623,
     "status": "aborted",
     "timestamp": 1609881728405,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "5p7RMwacWHr2"
   },
   "outputs": [],
   "source": [
    "movies = pd.read_csv('https://s3.amazonaws.com//abacusai.exampledatasets/user_recommendations/movies_metadata.csv', dtype=object)\n",
    "users = pd.read_csv('https://s3.amazonaws.com//abacusai.exampledatasets/user_recommendations/users_metadata.csv', dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ot-7qArxWfO6"
   },
   "source": [
    "### Select a User ID\n",
    "\n",
    "The first step is to select a user by inputting his/her user ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 115924,
     "status": "aborted",
     "timestamp": 1609881728406,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "CMtXh8t1VV8M"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "      <td>35-44</td>\n",
       "      <td>academic/educator</td>\n",
       "      <td>95370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id gender    age         occupation zip_code\n",
       "9      10      F  35-44  academic/educator    95370"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = \"10\" #@param {type: \"string\"}\n",
    "users[users[\"user_id\"] == user_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkUMlGr_334G"
   },
   "source": [
    "### Build the query\n",
    "\n",
    "The query is a dictionary with the key being the column used as **ITEM_ID** (in our example, the *movie_id* column) and the value being the corresponding ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 113723,
     "status": "aborted",
     "timestamp": 1609881728408,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "ryXudHNi36R2"
   },
   "outputs": [],
   "source": [
    "my_query_data = {\"user_id\": user_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R54Ti8zhdzcz"
   },
   "source": [
    "### Run the Get Recommendations API\n",
    "\n",
    "This command will return a list of recommendations for the user with the specified ID. The recommendation would be determined based on what movies the user liked in the past and how the movies and users are related to each other depending on their attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 112001,
     "status": "aborted",
     "timestamp": 1609881728410,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "IpBUO9EywV53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'movie_id': '1721'},\n",
       " {'movie_id': '1393'},\n",
       " {'movie_id': '2858'},\n",
       " {'movie_id': '593'},\n",
       " {'movie_id': '1183'},\n",
       " {'movie_id': '1639'},\n",
       " {'movie_id': '265'},\n",
       " {'movie_id': '17'},\n",
       " {'movie_id': '2959'},\n",
       " {'movie_id': '1907'},\n",
       " {'movie_id': '3147'},\n",
       " {'movie_id': '34'},\n",
       " {'movie_id': '1094'},\n",
       " {'movie_id': '1617'},\n",
       " {'movie_id': '3044'},\n",
       " {'movie_id': '266'},\n",
       " {'movie_id': '608'},\n",
       " {'movie_id': '296'},\n",
       " {'movie_id': '531'},\n",
       " {'movie_id': '58'},\n",
       " {'movie_id': '25'},\n",
       " {'movie_id': '151'},\n",
       " {'movie_id': '11'},\n",
       " {'movie_id': '2028'},\n",
       " {'movie_id': '912'},\n",
       " {'movie_id': '1092'},\n",
       " {'movie_id': '2329'},\n",
       " {'movie_id': '1625'},\n",
       " {'movie_id': '2890'},\n",
       " {'movie_id': '509'},\n",
       " {'movie_id': '2687'},\n",
       " {'movie_id': '3148'},\n",
       " {'movie_id': '1266'},\n",
       " {'movie_id': '50'},\n",
       " {'movie_id': '39'},\n",
       " {'movie_id': '1680'},\n",
       " {'movie_id': '2710'},\n",
       " {'movie_id': '2908'},\n",
       " {'movie_id': '2085'},\n",
       " {'movie_id': '3252'},\n",
       " {'movie_id': '534'},\n",
       " {'movie_id': '3897'},\n",
       " {'movie_id': '1358'},\n",
       " {'movie_id': '3105'},\n",
       " {'movie_id': '529'},\n",
       " {'movie_id': '1093'},\n",
       " {'movie_id': '1247'},\n",
       " {'movie_id': '908'},\n",
       " {'movie_id': '661'},\n",
       " {'movie_id': '222'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations = ApiClient().get_recommendations(\n",
    "    deployment_token=deployment_token, \n",
    "    deployment_id=recommendations_deployment.deployment_id, \n",
    "    query_data=my_query_data,\n",
    ")\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0NhqJull-Ft"
   },
   "source": [
    "A convenient way to visualize the data is within a Pandas Dataframe, by joining it with the movies dataframe to have the movies' names and genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 108754,
     "status": "aborted",
     "timestamp": 1609881728411,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "SzPjHdiHl-eS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1721</td>\n",
       "      <td>Titanic (1997)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1393</td>\n",
       "      <td>Jerry Maguire (1996)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2858</td>\n",
       "      <td>American Beauty (1999)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>Silence of the Lambs, The (1991)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1183</td>\n",
       "      <td>English Patient, The (1996)</td>\n",
       "      <td>Drama|Romance|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1639</td>\n",
       "      <td>Chasing Amy (1997)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>265</td>\n",
       "      <td>Like Water for Chocolate (Como agua para chocolate) (1992)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>Sense and Sensibility (1995)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2959</td>\n",
       "      <td>Fight Club (1999)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1907</td>\n",
       "      <td>Mulan (1998)</td>\n",
       "      <td>Animation|Children's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3147</td>\n",
       "      <td>Green Mile, The (1999)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>34</td>\n",
       "      <td>Babe (1995)</td>\n",
       "      <td>Children's|Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1094</td>\n",
       "      <td>Crying Game, The (1992)</td>\n",
       "      <td>Drama|Romance|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1617</td>\n",
       "      <td>L.A. Confidential (1997)</td>\n",
       "      <td>Crime|Film-Noir|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3044</td>\n",
       "      <td>Dead Again (1991)</td>\n",
       "      <td>Mystery|Romance|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>266</td>\n",
       "      <td>Legends of the Fall (1994)</td>\n",
       "      <td>Drama|Romance|War|Western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>608</td>\n",
       "      <td>Fargo (1996)</td>\n",
       "      <td>Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>296</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>531</td>\n",
       "      <td>Secret Garden, The (1993)</td>\n",
       "      <td>Children's|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>58</td>\n",
       "      <td>Postino, Il (The Postman) (1994)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>25</td>\n",
       "      <td>Leaving Las Vegas (1995)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>151</td>\n",
       "      <td>Rob Roy (1995)</td>\n",
       "      <td>Drama|Romance|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11</td>\n",
       "      <td>American President, The (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2028</td>\n",
       "      <td>Saving Private Ryan (1998)</td>\n",
       "      <td>Action|Drama|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>912</td>\n",
       "      <td>Casablanca (1942)</td>\n",
       "      <td>Drama|Romance|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1092</td>\n",
       "      <td>Basic Instinct (1992)</td>\n",
       "      <td>Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2329</td>\n",
       "      <td>American History X (1998)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1625</td>\n",
       "      <td>Game, The (1997)</td>\n",
       "      <td>Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2890</td>\n",
       "      <td>Three Kings (1999)</td>\n",
       "      <td>Drama|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>509</td>\n",
       "      <td>Piano, The (1993)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2687</td>\n",
       "      <td>Tarzan (1999)</td>\n",
       "      <td>Animation|Children's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3148</td>\n",
       "      <td>Cider House Rules, The (1999)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1266</td>\n",
       "      <td>Unforgiven (1992)</td>\n",
       "      <td>Western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>Crime|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>39</td>\n",
       "      <td>Clueless (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1680</td>\n",
       "      <td>Sliding Doors (1998)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2710</td>\n",
       "      <td>Blair Witch Project, The (1999)</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2908</td>\n",
       "      <td>Boys Don't Cry (1999)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2085</td>\n",
       "      <td>101 Dalmatians (1961)</td>\n",
       "      <td>Animation|Children's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3252</td>\n",
       "      <td>Scent of a Woman (1992)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>534</td>\n",
       "      <td>Shadowlands (1993)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3897</td>\n",
       "      <td>Almost Famous (2000)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1358</td>\n",
       "      <td>Sling Blade (1996)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3105</td>\n",
       "      <td>Awakenings (1990)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>529</td>\n",
       "      <td>Searching for Bobby Fischer (1993)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1093</td>\n",
       "      <td>Doors, The (1991)</td>\n",
       "      <td>Drama|Musical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1247</td>\n",
       "      <td>Graduate, The (1967)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>908</td>\n",
       "      <td>North by Northwest (1959)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>661</td>\n",
       "      <td>James and the Giant Peach (1996)</td>\n",
       "      <td>Animation|Children's|Musical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>222</td>\n",
       "      <td>Circle of Friends (1995)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                                       movie  \\\n",
       "0      1721                                              Titanic (1997)   \n",
       "1      1393                                        Jerry Maguire (1996)   \n",
       "2      2858                                      American Beauty (1999)   \n",
       "3       593                            Silence of the Lambs, The (1991)   \n",
       "4      1183                                 English Patient, The (1996)   \n",
       "5      1639                                          Chasing Amy (1997)   \n",
       "6       265  Like Water for Chocolate (Como agua para chocolate) (1992)   \n",
       "7        17                                Sense and Sensibility (1995)   \n",
       "8      2959                                           Fight Club (1999)   \n",
       "9      1907                                                Mulan (1998)   \n",
       "10     3147                                      Green Mile, The (1999)   \n",
       "11       34                                                 Babe (1995)   \n",
       "12     1094                                     Crying Game, The (1992)   \n",
       "13     1617                                    L.A. Confidential (1997)   \n",
       "14     3044                                           Dead Again (1991)   \n",
       "15      266                                  Legends of the Fall (1994)   \n",
       "16      608                                                Fargo (1996)   \n",
       "17      296                                         Pulp Fiction (1994)   \n",
       "18      531                                   Secret Garden, The (1993)   \n",
       "19       58                            Postino, Il (The Postman) (1994)   \n",
       "20       25                                    Leaving Las Vegas (1995)   \n",
       "21      151                                              Rob Roy (1995)   \n",
       "22       11                              American President, The (1995)   \n",
       "23     2028                                  Saving Private Ryan (1998)   \n",
       "24      912                                           Casablanca (1942)   \n",
       "25     1092                                       Basic Instinct (1992)   \n",
       "26     2329                                   American History X (1998)   \n",
       "27     1625                                            Game, The (1997)   \n",
       "28     2890                                          Three Kings (1999)   \n",
       "29      509                                           Piano, The (1993)   \n",
       "30     2687                                               Tarzan (1999)   \n",
       "31     3148                               Cider House Rules, The (1999)   \n",
       "32     1266                                           Unforgiven (1992)   \n",
       "33       50                                  Usual Suspects, The (1995)   \n",
       "34       39                                             Clueless (1995)   \n",
       "35     1680                                        Sliding Doors (1998)   \n",
       "36     2710                             Blair Witch Project, The (1999)   \n",
       "37     2908                                       Boys Don't Cry (1999)   \n",
       "38     2085                                       101 Dalmatians (1961)   \n",
       "39     3252                                     Scent of a Woman (1992)   \n",
       "40      534                                          Shadowlands (1993)   \n",
       "41     3897                                        Almost Famous (2000)   \n",
       "42     1358                                          Sling Blade (1996)   \n",
       "43     3105                                           Awakenings (1990)   \n",
       "44      529                          Searching for Bobby Fischer (1993)   \n",
       "45     1093                                           Doors, The (1991)   \n",
       "46     1247                                        Graduate, The (1967)   \n",
       "47      908                                   North by Northwest (1959)   \n",
       "48      661                            James and the Giant Peach (1996)   \n",
       "49      222                                    Circle of Friends (1995)   \n",
       "\n",
       "                              genres  \n",
       "0                      Drama|Romance  \n",
       "1                      Drama|Romance  \n",
       "2                       Comedy|Drama  \n",
       "3                     Drama|Thriller  \n",
       "4                  Drama|Romance|War  \n",
       "5                      Drama|Romance  \n",
       "6                      Drama|Romance  \n",
       "7                      Drama|Romance  \n",
       "8                              Drama  \n",
       "9               Animation|Children's  \n",
       "10                    Drama|Thriller  \n",
       "11           Children's|Comedy|Drama  \n",
       "12                 Drama|Romance|War  \n",
       "13  Crime|Film-Noir|Mystery|Thriller  \n",
       "14          Mystery|Romance|Thriller  \n",
       "15         Drama|Romance|War|Western  \n",
       "16              Crime|Drama|Thriller  \n",
       "17                       Crime|Drama  \n",
       "18                  Children's|Drama  \n",
       "19                     Drama|Romance  \n",
       "20                     Drama|Romance  \n",
       "21                 Drama|Romance|War  \n",
       "22              Comedy|Drama|Romance  \n",
       "23                  Action|Drama|War  \n",
       "24                 Drama|Romance|War  \n",
       "25                  Mystery|Thriller  \n",
       "26                             Drama  \n",
       "27                  Mystery|Thriller  \n",
       "28                         Drama|War  \n",
       "29                     Drama|Romance  \n",
       "30              Animation|Children's  \n",
       "31                             Drama  \n",
       "32                           Western  \n",
       "33                    Crime|Thriller  \n",
       "34                    Comedy|Romance  \n",
       "35                     Drama|Romance  \n",
       "36                            Horror  \n",
       "37                             Drama  \n",
       "38              Animation|Children's  \n",
       "39                             Drama  \n",
       "40                     Drama|Romance  \n",
       "41                      Comedy|Drama  \n",
       "42                    Drama|Thriller  \n",
       "43                             Drama  \n",
       "44                             Drama  \n",
       "45                     Drama|Musical  \n",
       "46                     Drama|Romance  \n",
       "47                    Drama|Thriller  \n",
       "48      Animation|Children's|Musical  \n",
       "49                     Drama|Romance  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_df = pd.DataFrame(recommendations).merge(movies, on=\"movie_id\")\n",
    "recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkqvGBWPH_7-"
   },
   "source": [
    "### Set the number of results per page\n",
    "\n",
    "For convenience, the number of recommendations is set to 50 per page by default. You can change the default value by editing the value of the `num_items` keyword. The example below sets the number of pages to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 106117,
     "status": "aborted",
     "timestamp": 1609881728413,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "ta77ndvjVQYN"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1721</td>\n",
       "      <td>Titanic (1997)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1393</td>\n",
       "      <td>Jerry Maguire (1996)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2858</td>\n",
       "      <td>American Beauty (1999)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>Silence of the Lambs, The (1991)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1183</td>\n",
       "      <td>English Patient, The (1996)</td>\n",
       "      <td>Drama|Romance|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1639</td>\n",
       "      <td>Chasing Amy (1997)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>265</td>\n",
       "      <td>Like Water for Chocolate (Como agua para chocolate) (1992)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>Sense and Sensibility (1995)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2959</td>\n",
       "      <td>Fight Club (1999)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1907</td>\n",
       "      <td>Mulan (1998)</td>\n",
       "      <td>Animation|Children's</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_id                                                       movie  \\\n",
       "0     1721                                              Titanic (1997)   \n",
       "1     1393                                        Jerry Maguire (1996)   \n",
       "2     2858                                      American Beauty (1999)   \n",
       "3      593                            Silence of the Lambs, The (1991)   \n",
       "4     1183                                 English Patient, The (1996)   \n",
       "5     1639                                          Chasing Amy (1997)   \n",
       "6      265  Like Water for Chocolate (Como agua para chocolate) (1992)   \n",
       "7       17                                Sense and Sensibility (1995)   \n",
       "8     2959                                           Fight Club (1999)   \n",
       "9     1907                                                Mulan (1998)   \n",
       "\n",
       "                 genres  \n",
       "0         Drama|Romance  \n",
       "1         Drama|Romance  \n",
       "2          Comedy|Drama  \n",
       "3        Drama|Thriller  \n",
       "4     Drama|Romance|War  \n",
       "5         Drama|Romance  \n",
       "6         Drama|Romance  \n",
       "7         Drama|Romance  \n",
       "8                 Drama  \n",
       "9  Animation|Children's  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_base = ApiClient().get_recommendations(\n",
    "    deployment_token=deployment_token, \n",
    "    deployment_id=recommendations_deployment.deployment_id, \n",
    "    query_data=my_query_data,\n",
    "    num_items=10,\n",
    ")\n",
    "recommendations_base_df = pd.DataFrame(recommendations_base).merge(movies, on=\"movie_id\")\n",
    "recommendations_base_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDBxTnhtNc_P"
   },
   "source": [
    "You can easily select the page to display with the keyword `page`. For example, let's say that the num_items is set to 10 with the total recommendations list size of 50 recommended items, then an input value of 2 in the `page` keyword will display a list of items that rank from 11th to 20th. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 103855,
     "status": "aborted",
     "timestamp": 1609881728414,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "DIh9_5bKNdh8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3147</td>\n",
       "      <td>Green Mile, The (1999)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>Babe (1995)</td>\n",
       "      <td>Children's|Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1094</td>\n",
       "      <td>Crying Game, The (1992)</td>\n",
       "      <td>Drama|Romance|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1617</td>\n",
       "      <td>L.A. Confidential (1997)</td>\n",
       "      <td>Crime|Film-Noir|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3044</td>\n",
       "      <td>Dead Again (1991)</td>\n",
       "      <td>Mystery|Romance|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>266</td>\n",
       "      <td>Legends of the Fall (1994)</td>\n",
       "      <td>Drama|Romance|War|Western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>608</td>\n",
       "      <td>Fargo (1996)</td>\n",
       "      <td>Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>296</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>531</td>\n",
       "      <td>Secret Garden, The (1993)</td>\n",
       "      <td>Children's|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>58</td>\n",
       "      <td>Postino, Il (The Postman) (1994)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_id                             movie                            genres\n",
       "0     3147            Green Mile, The (1999)                    Drama|Thriller\n",
       "1       34                       Babe (1995)           Children's|Comedy|Drama\n",
       "2     1094           Crying Game, The (1992)                 Drama|Romance|War\n",
       "3     1617          L.A. Confidential (1997)  Crime|Film-Noir|Mystery|Thriller\n",
       "4     3044                 Dead Again (1991)          Mystery|Romance|Thriller\n",
       "5      266        Legends of the Fall (1994)         Drama|Romance|War|Western\n",
       "6      608                      Fargo (1996)              Crime|Drama|Thriller\n",
       "7      296               Pulp Fiction (1994)                       Crime|Drama\n",
       "8      531         Secret Garden, The (1993)                  Children's|Drama\n",
       "9       58  Postino, Il (The Postman) (1994)                     Drama|Romance"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_page = ApiClient().get_recommendations(\n",
    "    deployment_token=deployment_token, \n",
    "    deployment_id=recommendations_deployment.deployment_id, \n",
    "    query_data={\"user_id\":user_id},\n",
    "    num_items=10,\n",
    "    page=2,\n",
    ")\n",
    "recommendations_page_df = pd.DataFrame(recommendations_page).merge(movies, on=\"movie_id\")\n",
    "recommendations_page_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdOn7Gn0dmiC"
   },
   "source": [
    "You can add a column with the relative item scores by specifying the column name for the keyword `score_field` (example: \"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 100093,
     "status": "aborted",
     "timestamp": 1609881728416,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "fq4czBfddKmE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>score</th>\n",
       "      <th>movie</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1721</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Titanic (1997)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1393</td>\n",
       "      <td>84.93</td>\n",
       "      <td>Jerry Maguire (1996)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2858</td>\n",
       "      <td>71.64</td>\n",
       "      <td>American Beauty (1999)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>68.05</td>\n",
       "      <td>Silence of the Lambs, The (1991)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1183</td>\n",
       "      <td>62.65</td>\n",
       "      <td>English Patient, The (1996)</td>\n",
       "      <td>Drama|Romance|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1639</td>\n",
       "      <td>56.81</td>\n",
       "      <td>Chasing Amy (1997)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>265</td>\n",
       "      <td>56.11</td>\n",
       "      <td>Like Water for Chocolate (Como agua para chocolate) (1992)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>55.29</td>\n",
       "      <td>Sense and Sensibility (1995)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2959</td>\n",
       "      <td>51.21</td>\n",
       "      <td>Fight Club (1999)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1907</td>\n",
       "      <td>45.51</td>\n",
       "      <td>Mulan (1998)</td>\n",
       "      <td>Animation|Children's</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_id   score  \\\n",
       "0     1721  100.00   \n",
       "1     1393   84.93   \n",
       "2     2858   71.64   \n",
       "3      593   68.05   \n",
       "4     1183   62.65   \n",
       "5     1639   56.81   \n",
       "6      265   56.11   \n",
       "7       17   55.29   \n",
       "8     2959   51.21   \n",
       "9     1907   45.51   \n",
       "\n",
       "                                                        movie  \\\n",
       "0                                              Titanic (1997)   \n",
       "1                                        Jerry Maguire (1996)   \n",
       "2                                      American Beauty (1999)   \n",
       "3                            Silence of the Lambs, The (1991)   \n",
       "4                                 English Patient, The (1996)   \n",
       "5                                          Chasing Amy (1997)   \n",
       "6  Like Water for Chocolate (Como agua para chocolate) (1992)   \n",
       "7                                Sense and Sensibility (1995)   \n",
       "8                                           Fight Club (1999)   \n",
       "9                                                Mulan (1998)   \n",
       "\n",
       "                 genres  \n",
       "0         Drama|Romance  \n",
       "1         Drama|Romance  \n",
       "2          Comedy|Drama  \n",
       "3        Drama|Thriller  \n",
       "4     Drama|Romance|War  \n",
       "5         Drama|Romance  \n",
       "6         Drama|Romance  \n",
       "7         Drama|Romance  \n",
       "8                 Drama  \n",
       "9  Animation|Children's  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_score = ApiClient().get_recommendations(\n",
    "    deployment_token=deployment_token, \n",
    "    deployment_id=recommendations_deployment.deployment_id, \n",
    "    query_data=my_query_data,\n",
    "    num_items=10,\n",
    "    score_field = \"score\"\n",
    ")\n",
    "recommendations_score_df = pd.DataFrame(recommendations_score).merge(movies, on=\"movie_id\")\n",
    "recommendations_score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26oU3n84dnRU"
   },
   "source": [
    "### Use of Scaling Factors to bias the model toward certain items\n",
    "\n",
    "You can use a scaling factor to add a bias toward certain items of your items datasets using the keyword `scaling_factor`. \n",
    "\n",
    "The input is a list of dictionaries where the format of each dictionary is as follows: {\"column\": \"col0\", \"values\": [\"value0\", \"value1\"], \"factor\": 1.1}. \n",
    "\n",
    "The command below is using scaling factors based on the column \"Genres\" to add positive bias to the comedies with a scaling factor of 3, and a negative bias to the dramas with a scaling factor of 0.25.\n",
    "\n",
    "We now have a Comedy in the second recommendation for user ID 10 (while in the unscaled run, there was no Comedy in the first 50 recommendations). Similarly there is no more Drama|Romance in her first 10 recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 96258,
     "status": "aborted",
     "timestamp": 1609881728417,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "xGzQ-4M8dTEM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>score</th>\n",
       "      <th>movie</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1721</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Titanic (1997)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1393</td>\n",
       "      <td>85.28</td>\n",
       "      <td>Jerry Maguire (1996)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2858</td>\n",
       "      <td>70.87</td>\n",
       "      <td>American Beauty (1999)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>67.25</td>\n",
       "      <td>Silence of the Lambs, The (1991)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1183</td>\n",
       "      <td>63.14</td>\n",
       "      <td>English Patient, The (1996)</td>\n",
       "      <td>Drama|Romance|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1639</td>\n",
       "      <td>56.94</td>\n",
       "      <td>Chasing Amy (1997)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>265</td>\n",
       "      <td>56.80</td>\n",
       "      <td>Like Water for Chocolate (Como agua para chocolate) (1992)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>55.99</td>\n",
       "      <td>Sense and Sensibility (1995)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2959</td>\n",
       "      <td>50.94</td>\n",
       "      <td>Fight Club (1999)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1907</td>\n",
       "      <td>45.70</td>\n",
       "      <td>Mulan (1998)</td>\n",
       "      <td>Animation|Children's</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_id   score  \\\n",
       "0     1721  100.00   \n",
       "1     1393   85.28   \n",
       "2     2858   70.87   \n",
       "3      593   67.25   \n",
       "4     1183   63.14   \n",
       "5     1639   56.94   \n",
       "6      265   56.80   \n",
       "7       17   55.99   \n",
       "8     2959   50.94   \n",
       "9     1907   45.70   \n",
       "\n",
       "                                                        movie  \\\n",
       "0                                              Titanic (1997)   \n",
       "1                                        Jerry Maguire (1996)   \n",
       "2                                      American Beauty (1999)   \n",
       "3                            Silence of the Lambs, The (1991)   \n",
       "4                                 English Patient, The (1996)   \n",
       "5                                          Chasing Amy (1997)   \n",
       "6  Like Water for Chocolate (Como agua para chocolate) (1992)   \n",
       "7                                Sense and Sensibility (1995)   \n",
       "8                                           Fight Club (1999)   \n",
       "9                                                Mulan (1998)   \n",
       "\n",
       "                 genres  \n",
       "0         Drama|Romance  \n",
       "1         Drama|Romance  \n",
       "2          Comedy|Drama  \n",
       "3        Drama|Thriller  \n",
       "4     Drama|Romance|War  \n",
       "5         Drama|Romance  \n",
       "6         Drama|Romance  \n",
       "7         Drama|Romance  \n",
       "8                 Drama  \n",
       "9  Animation|Children's  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_scaling = ApiClient().get_recommendations(\n",
    "    deployment_token=deployment_token, \n",
    "    deployment_id=recommendations_deployment.deployment_id, \n",
    "    query_data=my_query_data,\n",
    "    num_items=10,\n",
    "    score_field = \"score\",\n",
    "    scaling_factors=[\n",
    "        {\"column\": \"genres\", \"values\": [\"Comedy\"], \"factor\": 3},\n",
    "        {\"column\": \"genres\", \"values\": [\"Drama\"], \"factor\": 0.25},\n",
    "    ],\n",
    ")\n",
    "recommendations_scaling_df = pd.DataFrame(recommendations_scaling).merge(movies, on=\"movie_id\")\n",
    "recommendations_scaling_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jX9h_4weRPX"
   },
   "source": [
    "### Item exclusion\n",
    "\n",
    "You can also exclude certain items from the list of recommendations using the keyword `exclude_items`. The command below is removing with genres Comedy|Romance and Drama|Romance from the recommendations list for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 92759,
     "status": "aborted",
     "timestamp": 1609881728418,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "pmQsHG-eeR4l"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>score</th>\n",
       "      <th>movie</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1721</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Titanic (1997)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1393</td>\n",
       "      <td>84.93</td>\n",
       "      <td>Jerry Maguire (1996)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2858</td>\n",
       "      <td>71.64</td>\n",
       "      <td>American Beauty (1999)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>68.05</td>\n",
       "      <td>Silence of the Lambs, The (1991)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1183</td>\n",
       "      <td>62.65</td>\n",
       "      <td>English Patient, The (1996)</td>\n",
       "      <td>Drama|Romance|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1639</td>\n",
       "      <td>56.81</td>\n",
       "      <td>Chasing Amy (1997)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>265</td>\n",
       "      <td>56.11</td>\n",
       "      <td>Like Water for Chocolate (Como agua para chocolate) (1992)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>55.29</td>\n",
       "      <td>Sense and Sensibility (1995)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2959</td>\n",
       "      <td>51.21</td>\n",
       "      <td>Fight Club (1999)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1907</td>\n",
       "      <td>45.51</td>\n",
       "      <td>Mulan (1998)</td>\n",
       "      <td>Animation|Children's</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_id   score  \\\n",
       "0     1721  100.00   \n",
       "1     1393   84.93   \n",
       "2     2858   71.64   \n",
       "3      593   68.05   \n",
       "4     1183   62.65   \n",
       "5     1639   56.81   \n",
       "6      265   56.11   \n",
       "7       17   55.29   \n",
       "8     2959   51.21   \n",
       "9     1907   45.51   \n",
       "\n",
       "                                                        movie  \\\n",
       "0                                              Titanic (1997)   \n",
       "1                                        Jerry Maguire (1996)   \n",
       "2                                      American Beauty (1999)   \n",
       "3                            Silence of the Lambs, The (1991)   \n",
       "4                                 English Patient, The (1996)   \n",
       "5                                          Chasing Amy (1997)   \n",
       "6  Like Water for Chocolate (Como agua para chocolate) (1992)   \n",
       "7                                Sense and Sensibility (1995)   \n",
       "8                                           Fight Club (1999)   \n",
       "9                                                Mulan (1998)   \n",
       "\n",
       "                 genres  \n",
       "0         Drama|Romance  \n",
       "1         Drama|Romance  \n",
       "2          Comedy|Drama  \n",
       "3        Drama|Thriller  \n",
       "4     Drama|Romance|War  \n",
       "5         Drama|Romance  \n",
       "6         Drama|Romance  \n",
       "7         Drama|Romance  \n",
       "8                 Drama  \n",
       "9  Animation|Children's  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_excluded = ApiClient().get_recommendations(\n",
    "    deployment_token=deployment_token, \n",
    "    deployment_id=recommendations_deployment.deployment_id, \n",
    "    query_data=my_query_data,\n",
    "    score_field = \"score\",\n",
    "    exclude_items=[{\"column\": \"genres\", \"values\": [\"Comedy|Romance\", \"Drama|Romance\"]}],\n",
    "    num_items=10,\n",
    ")\n",
    "recommendations_excluded_df = pd.DataFrame(recommendations_excluded).merge(movies, on=\"movie_id\")\n",
    "recommendations_excluded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IoBA6nweUBq"
   },
   "source": [
    "### Item restriction\n",
    "\n",
    "You can also restrict the list of recommendations to certain items using the keyword `restrict_items`. \n",
    "\n",
    "The input is a list of dictionaries where the format of each dictionary is as follows: {\"column\": \"col0\", \"values\": [\"value0\", \"value1\", \"value3\", ...]}\n",
    "\n",
    "The command below is returning only comedies and dramas in the user recommendation list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 82586,
     "status": "aborted",
     "timestamp": 1609881728419,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "x3wsjV-FeVs9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>score</th>\n",
       "      <th>movie</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1721</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Titanic (1997)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1393</td>\n",
       "      <td>85.28</td>\n",
       "      <td>Jerry Maguire (1996)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2858</td>\n",
       "      <td>70.87</td>\n",
       "      <td>American Beauty (1999)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>67.25</td>\n",
       "      <td>Silence of the Lambs, The (1991)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1183</td>\n",
       "      <td>63.14</td>\n",
       "      <td>English Patient, The (1996)</td>\n",
       "      <td>Drama|Romance|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1639</td>\n",
       "      <td>56.94</td>\n",
       "      <td>Chasing Amy (1997)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>265</td>\n",
       "      <td>56.80</td>\n",
       "      <td>Like Water for Chocolate (Como agua para chocolate) (1992)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>55.99</td>\n",
       "      <td>Sense and Sensibility (1995)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2959</td>\n",
       "      <td>50.94</td>\n",
       "      <td>Fight Club (1999)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1907</td>\n",
       "      <td>45.70</td>\n",
       "      <td>Mulan (1998)</td>\n",
       "      <td>Animation|Children's</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_id   score  \\\n",
       "0     1721  100.00   \n",
       "1     1393   85.28   \n",
       "2     2858   70.87   \n",
       "3      593   67.25   \n",
       "4     1183   63.14   \n",
       "5     1639   56.94   \n",
       "6      265   56.80   \n",
       "7       17   55.99   \n",
       "8     2959   50.94   \n",
       "9     1907   45.70   \n",
       "\n",
       "                                                        movie  \\\n",
       "0                                              Titanic (1997)   \n",
       "1                                        Jerry Maguire (1996)   \n",
       "2                                      American Beauty (1999)   \n",
       "3                            Silence of the Lambs, The (1991)   \n",
       "4                                 English Patient, The (1996)   \n",
       "5                                          Chasing Amy (1997)   \n",
       "6  Like Water for Chocolate (Como agua para chocolate) (1992)   \n",
       "7                                Sense and Sensibility (1995)   \n",
       "8                                           Fight Club (1999)   \n",
       "9                                                Mulan (1998)   \n",
       "\n",
       "                 genres  \n",
       "0         Drama|Romance  \n",
       "1         Drama|Romance  \n",
       "2          Comedy|Drama  \n",
       "3        Drama|Thriller  \n",
       "4     Drama|Romance|War  \n",
       "5         Drama|Romance  \n",
       "6         Drama|Romance  \n",
       "7         Drama|Romance  \n",
       "8                 Drama  \n",
       "9  Animation|Children's  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_restricted = ApiClient().get_recommendations(\n",
    "    deployment_token=deployment_token, \n",
    "    deployment_id=recommendations_deployment.deployment_id, \n",
    "    query_data=my_query_data,\n",
    "    score_field = \"score\",\n",
    "    restrict_items=[{\"column\": \"genres\", \"values\": [\"Comedy\", \"Drama\"]}],\n",
    "    num_items=10,\n",
    ")\n",
    "recommendations_restricted_df = pd.DataFrame(recommendations_restricted).merge(movies, on=\"movie_id\")\n",
    "recommendations_restricted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyCQKAfDU3SV"
   },
   "source": [
    "### Compare the different user recommendations\n",
    "\n",
    "We can compare the recommendation results with pandas commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 74143,
     "status": "aborted",
     "timestamp": 1609881728421,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "Ojwe-7JrU-OI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Without Filter</th>\n",
       "      <th>With Scaling Factor</th>\n",
       "      <th>With Exclusion List</th>\n",
       "      <th>With Restricted List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Titanic (1997)</td>\n",
       "      <td>Titanic (1997)</td>\n",
       "      <td>Titanic (1997)</td>\n",
       "      <td>Titanic (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jerry Maguire (1996)</td>\n",
       "      <td>Jerry Maguire (1996)</td>\n",
       "      <td>Jerry Maguire (1996)</td>\n",
       "      <td>Jerry Maguire (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American Beauty (1999)</td>\n",
       "      <td>American Beauty (1999)</td>\n",
       "      <td>American Beauty (1999)</td>\n",
       "      <td>American Beauty (1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Silence of the Lambs, The (1991)</td>\n",
       "      <td>Silence of the Lambs, The (1991)</td>\n",
       "      <td>Silence of the Lambs, The (1991)</td>\n",
       "      <td>Silence of the Lambs, The (1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English Patient, The (1996)</td>\n",
       "      <td>English Patient, The (1996)</td>\n",
       "      <td>English Patient, The (1996)</td>\n",
       "      <td>English Patient, The (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chasing Amy (1997)</td>\n",
       "      <td>Chasing Amy (1997)</td>\n",
       "      <td>Chasing Amy (1997)</td>\n",
       "      <td>Chasing Amy (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Like Water for Chocolate (Como agua para chocolate) (1992)</td>\n",
       "      <td>Like Water for Chocolate (Como agua para chocolate) (1992)</td>\n",
       "      <td>Like Water for Chocolate (Como agua para chocolate) (1992)</td>\n",
       "      <td>Like Water for Chocolate (Como agua para chocolate) (1992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sense and Sensibility (1995)</td>\n",
       "      <td>Sense and Sensibility (1995)</td>\n",
       "      <td>Sense and Sensibility (1995)</td>\n",
       "      <td>Sense and Sensibility (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fight Club (1999)</td>\n",
       "      <td>Fight Club (1999)</td>\n",
       "      <td>Fight Club (1999)</td>\n",
       "      <td>Fight Club (1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mulan (1998)</td>\n",
       "      <td>Mulan (1998)</td>\n",
       "      <td>Mulan (1998)</td>\n",
       "      <td>Mulan (1998)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Without Filter  \\\n",
       "0                                              Titanic (1997)   \n",
       "1                                        Jerry Maguire (1996)   \n",
       "2                                      American Beauty (1999)   \n",
       "3                            Silence of the Lambs, The (1991)   \n",
       "4                                 English Patient, The (1996)   \n",
       "5                                          Chasing Amy (1997)   \n",
       "6  Like Water for Chocolate (Como agua para chocolate) (1992)   \n",
       "7                                Sense and Sensibility (1995)   \n",
       "8                                           Fight Club (1999)   \n",
       "9                                                Mulan (1998)   \n",
       "\n",
       "                                          With Scaling Factor  \\\n",
       "0                                              Titanic (1997)   \n",
       "1                                        Jerry Maguire (1996)   \n",
       "2                                      American Beauty (1999)   \n",
       "3                            Silence of the Lambs, The (1991)   \n",
       "4                                 English Patient, The (1996)   \n",
       "5                                          Chasing Amy (1997)   \n",
       "6  Like Water for Chocolate (Como agua para chocolate) (1992)   \n",
       "7                                Sense and Sensibility (1995)   \n",
       "8                                           Fight Club (1999)   \n",
       "9                                                Mulan (1998)   \n",
       "\n",
       "                                          With Exclusion List  \\\n",
       "0                                              Titanic (1997)   \n",
       "1                                        Jerry Maguire (1996)   \n",
       "2                                      American Beauty (1999)   \n",
       "3                            Silence of the Lambs, The (1991)   \n",
       "4                                 English Patient, The (1996)   \n",
       "5                                          Chasing Amy (1997)   \n",
       "6  Like Water for Chocolate (Como agua para chocolate) (1992)   \n",
       "7                                Sense and Sensibility (1995)   \n",
       "8                                           Fight Club (1999)   \n",
       "9                                                Mulan (1998)   \n",
       "\n",
       "                                         With Restricted List  \n",
       "0                                              Titanic (1997)  \n",
       "1                                        Jerry Maguire (1996)  \n",
       "2                                      American Beauty (1999)  \n",
       "3                            Silence of the Lambs, The (1991)  \n",
       "4                                 English Patient, The (1996)  \n",
       "5                                          Chasing Amy (1997)  \n",
       "6  Like Water for Chocolate (Como agua para chocolate) (1992)  \n",
       "7                                Sense and Sensibility (1995)  \n",
       "8                                           Fight Club (1999)  \n",
       "9                                                Mulan (1998)  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.concat(\n",
    "    [\n",
    "        recommendations_base_df[\"movie\"],\n",
    "        recommendations_scaling_df[\"movie\"],\n",
    "        recommendations_excluded_df[\"movie\"],\n",
    "        recommendations_restricted_df[\"movie\"],\n",
    "    ],\n",
    "    axis=1,\n",
    "    ignore_index=True\n",
    ")\n",
    "dataframe.columns = [\"Without Filter\", \"With Scaling Factor\", \"With Exclusion List\", \"With Restricted List\"]\n",
    "dataframe"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Personalized Recommendations Notebook.ipynb",
   "provenance": [
    {
     "file_id": "1eGkb37EOSviuiOMYdc74ahPMS9eTkIIY",
     "timestamp": 1609882872216
    },
    {
     "file_id": "https://github.com/abacusai/notebooks/blob/main/Use%20Cases/Personalized%20Recommendations%20Notebook.ipynb",
     "timestamp": 1607911901788
    }
   ],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
